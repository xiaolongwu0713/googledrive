{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1oNSddmPYT8S4F9Ngr6nwU3pTPIoHVSQs","authorship_tag":"ABX9TyO9lccG2DT2+QHl16CZZu0r"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CYz-P2Bj7TIm"},"source":["Below are result using overlapped train/test dataset!!!!!\n","# 1.   Vision transformer(ViT):\n","\n","## windows=500\n","*   rawAndbands input: (windows/stride/accuracy)=500/50/98, 500/100/91, 500/200/77\n","*   raw input: (windows/stride/accuracy)= 500/50/99, 500/100/97, 500/200/83\n","\n","## windows=200\n","*  raw input: 200/200/44, 200/100/74, 200/50/90, \n","\n","\n","# 2. Deepnet\n","## windows=500\n","* rawAndbands:500/200/72%\n","* raw input:500/50/83%; 500/100/75%; 500/200/53%\n","\n","## windows=200\n","\n","* rawAndbands\n","* raw input"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANOR3DiaMpoE","executionInfo":{"status":"ok","timestamp":1633921443125,"user_tz":-480,"elapsed":590,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"dbd332be-d862-480b-87be-2f0bcc1c9312"},"source":["%cd /content/drive/MyDrive/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","metadata":{"id":"75yR8ulWMu62"},"source":["%%capture\n","! pip install hdf5storage\n","! pip install mne==0.23.0\n","! pip install torch==1.7.0\n","! pip install Braindecode==0.5.1\n","! pip install timm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YceJc6WlQarV","executionInfo":{"status":"ok","timestamp":1633921522505,"user_tz":-480,"elapsed":20,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"63127685-cf08-49d6-8c5a-34b08a089eff"},"source":["import sys, os, re\n","location=os.getcwd()\n","if len(sys.argv)>1: # command line\n","    sid = sys.argv[1]\n","    print(\"Running from CMD\")\n","    print('Python%son%s'%(sys.version,sys.platform))\n","    sys.path.extend(['/Users/long/Documents/BCI/python_scripts/googleDrive'])\n","else: # IDE\n","    print(\"Running from IDE\")\n","    sid=2\n","\n","if re.compile('/content/drive').match(location): # google colab\n","    sid=2\n","\n","print(\"processing on sid:\" + str(sid) + '.')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running from CMD\n","Python3.7.12 (default, Sep 10 2021, 00:21:48) \n","[GCC 7.5.0]onlinux\n","processing on sid:2.\n"]}]},{"cell_type":"code","metadata":{"id":"YAiYT0gbMyaX"},"source":["import scipy.io\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import mne\n","import torch\n","from torch.optim import lr_scheduler\n","from torch import nn\n","import timm\n","from common_dl import myDataset\n","from comm_utils import slide_epochs\n","from torch.utils.data import DataLoader\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from common_dl import set_random_seeds\n","from common_dsp import *\n","from gesture.models.d2l_resnet import d2lresnet\n","from myskorch import on_epoch_begin_callback, on_batch_end_callback\n","from ecog_finger.config import *\n","from ecog_finger.preprocess.chn_settings import  get_channel_setting\n","from gesture.models.deepmodel import deepnet\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttjDznmjbrg9"},"source":["seed = 20200220  # random seed to make results reproducible\n","set_random_seeds(seed=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkgUv_2zM0_9"},"source":["try:\n","    mne.set_config('MNE_LOGGING_LEVEL','ERROR')\n","except TypeError as err:\n","    print(err)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NBuF2-rM2Os"},"source":["fs=1000\n","class_number=5\n","use_active_only=False\n","if use_active_only:\n","    active_chn=get_channel_setting(sid)\n","else:\n","    active_chn='all'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYAJF-LRVYlO"},"source":["project_dir=data_dir+'fingerflex/data/'+str(sid)+'/'\n","model_path=project_dir + 'pth' +'/'\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","#input='rawAndbands'\n","input='raw'\n","if input=='raw':\n","    filename=project_dir + str(sid)+'_fingerflex.mat'\n","    mat=scipy.io.loadmat(filename)\n","    data=mat['data'] # (46, 610040)\n","    # timm expect even channels\n","    chn_num=data.shape[0]\n","    if chn_num%2:# even channels\n","        pass\n","    else:\n","        data=np.concatenate((data, data[-1,:]),axis=0)\n","\n","    #data=data[:,:-1]\n","\n","    if 1==1:\n","        scaler = StandardScaler()\n","        scaler.fit(data)\n","        data=scaler.transform((data))\n","    data=np.transpose(data)\n","    chn_num=data.shape[0]\n","    flex=np.transpose(mat['flex']) #(5, 610040)\n","    cue=np.transpose(mat['cue']) # (1, 610040)\n","    data=np.concatenate((data,cue),axis=0) # (47, 610040) / (47, 610040)\n","\n","    chn_names=np.append([\"ecog\"]*chn_num,[\"stim\"])  #,\"thumb\",\"index\",\"middle\",\"ring\",\"little\"])\n","    chn_types=np.append([\"ecog\"]*chn_num,[\"stim\"])  #, \"emg\",\"emg\",\"emg\",\"emg\",\"emg\"])\n","    info = mne.create_info(ch_names=list(chn_names), ch_types=list(chn_types), sfreq=fs)\n","    raw = mne.io.RawArray(data, info)\n","\n","    events = mne.find_events(raw, stim_channel='stim')\n","    events=events-[0,0,1] #(150, 3)\n","    raw=raw.pick(picks=['ecog'])\n","\n","\n","    epochs = mne.Epochs(raw, events, tmin=0, tmax=2,baseline=None)\n","    # or epoch from 0s to 4s which only contain movement data.\n","    # epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)\n","\n","    epoch1=epochs['0'].get_data() # 20 trials. 8001 time points per trial for 8s.\n","    epoch2=epochs['1'].get_data()\n","    epoch3=epochs['2'].get_data()\n","    epoch4=epochs['3'].get_data()\n","    epoch5=epochs['4'].get_data()\n","    list_of_epochs = [epoch1, epoch2, epoch3, epoch4, epoch5]\n","    chn_num=epoch1.shape[1]\n","\n","elif input=='rawAndbands':\n","    list_of_epochs=[]\n","    save_to = data_dir + 'fingerflex/data/' + str(sid) + '/'\n","    for fingeri in range(5):\n","        tmp = mne.read_epochs(save_to + 'rawBandEpoch'+str(fingeri)+'.fif')\n","        list_of_epochs.append(tmp.get_data())\n","    chn_num=list_of_epochs[0].shape[1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8aGvAGWIbAD"},"source":["\n","# validate=test=2 trials\n","trial_number=[list(range(epochi.shape[0])) for epochi in list_of_epochs] #[ [0,1,2,...29],[0,1,2...29],... ]\n","test_trials=[random.sample(epochi, 2) for epochi in trial_number]\n","# len(test_trials[0]) # test trials number\n","trial_number_left=[np.setdiff1d(trial_number[i],test_trials[i]) for i in range(class_number)]\n","\n","val_trials=[random.sample(list(epochi), 2) for epochi in trial_number_left]\n","train_trials=[np.setdiff1d(trial_number_left[i],val_trials[i]).tolist() for i in range(class_number)]\n","\n","# no missing trials\n","assert [sorted(test_trials[i]+val_trials[i]+train_trials[i]) for i in range(class_number)] == trial_number\n","\n","test_epochs=[epochi[test_trials[clas],:,:] for clas,epochi in enumerate(list_of_epochs)] # [ epoch0,epoch1,epch2,epoch3,epoch4 ]\n","val_epochs=[epochi[val_trials[clas],:,:] for clas,epochi in enumerate(list_of_epochs)]\n","train_epochs=[epochi[train_trials[clas],:,:] for clas,epochi in enumerate(list_of_epochs)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nIelezDjIh8J"},"source":["\n","wind=500\n","stride=50\n","X_train=[]\n","y_train=[]\n","X_val=[]\n","y_val=[]\n","X_test=[]\n","y_test=[]\n","\n","for clas, epochi in enumerate(test_epochs):\n","    Xi,y=slide_epochs(epochi,clas,wind, stride)\n","    assert Xi.shape[0]==len(y)\n","    X_test.append(Xi)\n","    y_test.append(y)\n","X_test=np.concatenate(X_test,axis=0) # (1300, 63, 500)\n","y_test=np.asarray(y_test)\n","y_test=np.reshape(y_test,(-1,1)) # (5, 270)\n","\n","for clas, epochi in enumerate(val_epochs):\n","    Xi,y=slide_epochs(epochi,clas,wind, stride)\n","    assert Xi.shape[0]==len(y)\n","    X_val.append(Xi)\n","    y_val.append(y)\n","X_val=np.concatenate(X_val,axis=0) # (1300, 63, 500)\n","y_val=np.asarray(y_val)\n","y_val=np.reshape(y_val,(-1,1)) # (5, 270)\n","\n","for clas, epochi in enumerate(train_epochs):\n","    Xi,y=slide_epochs(epochi,clas,wind, stride)\n","    assert Xi.shape[0]==len(y)\n","    X_train.append(Xi)\n","    y_train.append(y)\n","X_train=np.concatenate(X_train,axis=0) # (1300, 63, 500)\n","y_train=np.asarray(y_train)\n","y_train=np.reshape(y_train,(-1,1)) # (5, 270)\n","chn_num=X_train.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WelESGUdNN2q"},"source":["train_set=myDataset(X_train,y_train)\n","val_set=myDataset(X_val,y_val)\n","test_set=myDataset(X_test,y_test)\n","\n","batch_size = 32\n","train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n","val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n","test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZsxxcEaj6sy"},"source":["train_size=len(train_loader.dataset)\n","val_size=len(val_loader.dataset)\n","test_size=len(test_loader.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwqm_nOlNQKd"},"source":["cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n","device = 'cuda' if cuda else 'cpu'\n","if cuda:\n","    torch.backends.cudnn.benchmark = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxs7p8ikNSOX"},"source":["#net=d2lresnet()\n","img_size=[chn_num,wind]\n","net = timm.create_model('visformer_tiny',num_classes=5,in_chans=1,img_size=img_size)\n","#net = deepnet(chn_number,n_class,input_window_samples=wind,final_conv_length='auto',) # 81%\n","net = net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VY-5J7PbIV_"},"source":["lr = 0.05\n","weight_decay = 1e-10\n","epoch_num = 500\n","\n","criterion = nn.CrossEntropyLoss()\n","#criterion = nn.NLLLoss()\n","#optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n","optimizer = torch.optim.Adadelta(net.parameters(), lr=lr)\n","#optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","# Decay LR by a factor of 0.1 every 7 epochs\n","lr_schedulerr = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","epoch_num = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UFwHkb2dNXER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633921721997,"user_tz":-480,"elapsed":190275,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"90fcca41-8216-4abb-bc34-c490bcae69df"},"source":["for epoch in range(epoch_num):\n","    print(\"------ epoch \" + str(epoch) + \" -----\")\n","    net.train()\n","\n","    loss_epoch = 0\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    for batch, (trainx, trainy) in enumerate(train_loader):\n","        if isinstance(net, timm.models.visformer.Visformer):\n","            trainx=torch.unsqueeze(trainx,dim=1)\n","        optimizer.zero_grad()\n","        if (cuda):\n","            trainx = trainx.float().cuda()\n","        else:\n","            trainx = trainx.float()\n","        y_pred = net(trainx)\n","        #print(\"y_pred shape: \" + str(y_pred.shape))\n","        preds = y_pred.argmax(dim=1, keepdim=True)\n","        #_, preds = torch.max(y_pred, 1)\n","\n","        if cuda:\n","            loss = criterion(y_pred, trainy.squeeze().cuda().long())\n","        else:\n","            loss = criterion(y_pred, trainy.squeeze())\n","\n","        loss.backward()  # calculate the gradient and store in .grad attribute.\n","        optimizer.step()\n","        running_loss += loss.item() * trainx.shape[0]\n","        running_corrects += torch.sum(preds.cpu().squeeze() == trainy.squeeze())\n","    #print(\"train_size: \" + str(train_size))\n","    lr_schedulerr.step() # test it\n","    epoch_loss = running_loss / train_size\n","    epoch_acc = running_corrects.double() / train_size\n","    print(\"Training loss: {:.2f}; Accuracy: {:.2f}.\".format(epoch_loss,epoch_acc.item()))\n","    #print(\"Training \" + str(epoch) + \": loss: \" + str(epoch_loss) + \",\" + \"Accuracy: \" + str(epoch_acc.item()) + \".\")\n","\n","    state = {\n","            'net': net.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","             'epoch': epoch,\n","             'loss': epoch_loss\n","        }\n","    savepath = model_path + 'checkpoint' + str(epoch) + '.pth'\n","    #torch.save(state, savepath)\n","    running_loss = 0.0\n","    running_corrects = 0\n","    if epoch % 1 == 0:\n","        net.eval()\n","        # print(\"Validating...\")\n","        with torch.no_grad():\n","            for _, (val_x, val_y) in enumerate(val_loader):\n","                if isinstance(net, timm.models.visformer.Visformer):\n","                    val_x = torch.unsqueeze(val_x, dim=1)\n","                if (cuda):\n","                    val_x = val_x.float().cuda()\n","                    # val_y = val_y.float().cuda()\n","                else:\n","                    val_x = val_x.float()\n","                    # val_y = val_y.float()\n","                outputs = net(val_x)\n","                #_, preds = torch.max(outputs, 1)\n","                preds = outputs.argmax(dim=1, keepdim=True)\n","\n","                running_corrects += torch.sum(preds.cpu().squeeze() == val_y.squeeze())\n","\n","        epoch_acc = running_corrects.double() / val_size\n","        print(\"Evaluation accuracy: {:.2f}.\".format(epoch_acc.item()))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------ epoch 0 -----\n","Training loss: 1.09; Accuracy: 0.57.\n","Evaluation accuracy: 0.45.\n","------ epoch 1 -----\n","Training loss: 0.44; Accuracy: 0.85.\n","Evaluation accuracy: 0.40.\n","------ epoch 2 -----\n","Training loss: 0.18; Accuracy: 0.95.\n","Evaluation accuracy: 0.36.\n","------ epoch 3 -----\n","Training loss: 0.08; Accuracy: 0.98.\n","Evaluation accuracy: 0.47.\n","------ epoch 4 -----\n","Training loss: 0.05; Accuracy: 0.99.\n","Evaluation accuracy: 0.45.\n","------ epoch 5 -----\n","Training loss: 0.02; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 6 -----\n","Training loss: 0.02; Accuracy: 1.00.\n","Evaluation accuracy: 0.41.\n","------ epoch 7 -----\n","Training loss: 0.02; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 8 -----\n","Training loss: 0.02; Accuracy: 1.00.\n","Evaluation accuracy: 0.47.\n","------ epoch 9 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 10 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.41.\n","------ epoch 11 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.48.\n","------ epoch 12 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.48.\n","------ epoch 13 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.40.\n","------ epoch 14 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.47.\n","------ epoch 15 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.47.\n","------ epoch 16 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 17 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 18 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 19 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n"]}]},{"cell_type":"code","metadata":{"id":"Nv-zbCVueV75"},"source":["load_epoch=range(20)\n","#load_epoch=load_epoch[10]\n","net_test = timm.create_model('visformer_tiny',num_classes=5,in_chans=1,img_size=img_size)\n","net_test = net.to(device)\n","optimizer = torch.optim.Adadelta(net_test.parameters(), lr=lr)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dj227FHByFPh","colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"status":"error","timestamp":1633921722661,"user_tz":-480,"elapsed":675,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"5b8e7291-13b5-48e2-c9f6-25edbf508320"},"source":["test_acc=[]\n","for test_epoch in load_epoch:\n","\n","    running_corrects = 0\n","\n","    load_path=model_path + 'checkpoint' + str(test_epoch) + '.pth'\n","    checkpoint=torch.load(load_path)\n","    net_test.load_state_dict(checkpoint['net'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    net_test.eval()\n","\n","    # print(\"Validating...\")\n","    with torch.no_grad():\n","        for _, (test_x, test_y) in enumerate(test_loader):\n","            if isinstance(net, timm.models.visformer.Visformer):\n","                test_x = torch.unsqueeze(test_x, dim=1)\n","            if (cuda):\n","                test_x = test_x.float().cuda()\n","            else:\n","                test_x = test_x.float()\n","            outputs = net_test(test_x)\n","            #_, preds = torch.max(outputs, 1)\n","            preds = outputs.argmax(dim=1, keepdim=True)\n","\n","            running_corrects += torch.sum(preds.cpu().squeeze() == test_y.squeeze())\n","\n","    test_acci = running_corrects.double() / test_size\n","    print(\"Evaluation accuracy: {:.2f}.\".format(test_acci.item()))\n","    test_acc.append(test_acci.item())\n","test_acc=np.asarray(test_acc)\n","filename=project_dir+'test_acc'\n","np.save(filename,test_acc)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-d2b6ed87f3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mload_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'checkpoint'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnet_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnet_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Visformer:\n\tsize mismatch for pos_embed1: copying a param with shape torch.Size([1, 96, 62, 62]) from checkpoint, the shape in current model is torch.Size([1, 96, 7, 62]).\n\tsize mismatch for pos_embed2: copying a param with shape torch.Size([1, 192, 31, 31]) from checkpoint, the shape in current model is torch.Size([1, 192, 3, 31]).\n\tsize mismatch for pos_embed3: copying a param with shape torch.Size([1, 384, 15, 15]) from checkpoint, the shape in current model is torch.Size([1, 384, 1, 15])."]}]}]}