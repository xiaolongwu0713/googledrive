# raw data generated by preprocessing scripts in Matlab temporally

import hdf5storage
import h5py
import os
import numpy as np
import matplotlib.pyplot as plt
from mne.time_frequency import tfr_morlet

from gesture.config import *
from gesture.preprocess.chn_settings import get_channel_setting


sid=10 #4
data_dir='/Volumes/Samsung_T5/data/gesture/preprocessing/P'+str(sid)
output_dir=data_dir + '/tfInput/'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

Session_num,UseChn,EmgChn,TrigChn, activeChn = get_channel_setting(sid)
# choose less channel
activeChn=[57,]+[*range(147,150)]+[158,]+[*range(165,168)]+[180,183]
#activeChn=[168,180,183]
chn_num=len(activeChn)
#original_fs=[Frequencies[i,1] for i in range(Frequencies.shape[0]) if Frequencies[i,0] == pn][0]
fs=1000
loadPath = data_dir+'/preprocessing2.mat'
mat=hdf5storage.loadmat(loadPath)
data = mat['Datacell']
channelNum=int(mat['channelNum'][0,0])
data=np.concatenate((data[0,0],data[0,1]),0)
del mat

# stim0 is trigger channel, stim1 is trigger position calculated from EMG signal.
chn_names=np.append(["seeg"]*len(UseChn),["stim0", "emg","stim1"])
chn_types=np.append(["seeg"]*len(UseChn),["stim", "emg","stim"])
info = mne.create_info(ch_names=list(chn_names), ch_types=list(chn_types), sfreq=fs)
raw = mne.io.RawArray(data.transpose(), info)

# gesture/events type: 1,2,3,4,5
events0 = mne.find_events(raw, stim_channel='stim0')
events1 = mne.find_events(raw, stim_channel='stim1')
# events number should start from 0: 0,1,2,3,4, instead of 1,2,3,4,5
events0=events0-[0,0,1]
events1=events1-[0,0,1]

#print(events[:5])  # show the first 5
raw=raw.pick(["seeg"])
raw=raw.pick(activeChn)

# 0 second means the gesture onset time, tmin=-4 means 4 seconds before onset.
# movement lasts for 5s from 0s onest.
epochs = mne.Epochs(raw, events1, tmin=-4, tmax=6,baseline=None)
# or epoch from 0s to 4s which only contain movement data.
# epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)

# tf analysis on one epoch
epoch1=epochs['0'] # 20 trials. 8001 time points per trial for 8s.
epoch2=epochs['1']
epoch3=epochs['2']
epoch4=epochs['3']
epoch5=epochs['4']
list_of_epochs=[epoch1,epoch2,epoch3,epoch4,epoch5]
del epochs


## frequency analysis
# define frequencies of interest (log-spaced)
fMin,fMax=2,150
fstep=1
freqs=np.arange(fMin,fMax,fstep) #148
n_cycles=freqs/2

decim=4
new_fs=1000/decim
tf_input_tmp=[]
for i in range(5):
    epoch_tfr=tfr_morlet(list_of_epochs[i],freqs=freqs, n_cycles=n_cycles,use_fft=True,return_itc=False, average=False, decim=decim, n_jobs=1)
    epoch_tfr.apply_baseline([-3.5,0])
    epoch_tfr.crop(tmin=0,tmax=4) # (20, 10, 148, 1001)
    tf_input_tmp.append(epoch_tfr)

wind=int(1*new_fs)
stride=int(0.5*new_fs)
winds_per_trial=((tf_input_tmp[0].data[0].shape[2]-wind)//stride+1)
wind_num=winds_per_trial * len(epoch_tfr.events) # window number per trial * 20 trials in an epoch
wind_data=np.zeros((wind_num,chn_num,148,wind))
tf_input=[] #(5,140, 23, 148, 250): (5 movement, windows number, channel,frequency, time)
for i in range(5):
    tf_input.append([])
    tmp=tf_input_tmp[i].data # one epoch data,(20, 23, 148, 1001) (20 trials, 23 channels, 148*1001 tf 2D)
    for t in range(tmp.shape[0]): #iter through trials in epoch
    #for trial in tmp: # trial: (23, 148, 1001)
        trial=tmp[t]
        j=0
        while j<winds_per_trial:
            wind_data[t*winds_per_trial+j,:,:,:]=trial[:,:,j*stride:j*stride+wind]
            j=j+1
    tf_input[i]=wind_data
from sklearn.model_selection import train_test_split
y=[]
for i in range(5):
    tmp=[i]*wind_num
    y.append(tmp)

test_size=10 # training size=(140-10)*5; testing size=10*5
X_train_tmp=[]
X_test_tmp=[]
y_train_tmp=[]
y_test_tmp=[]
for i in range(5):
    X_train_tmp.append([])
    X_test_tmp.append([])
    y_train_tmp.append([])
    y_test_tmp.append([])
    X_train_tmp[i], X_test_tmp[i], y_train_tmp[i], y_test_tmp[i] = train_test_split(tf_input[i], y[i], test_size=10, random_state=42)

X_train=np.concatenate(X_train_tmp,axis=0)
X_test=np.concatenate(X_test_tmp,axis=0)
y_train=np.concatenate(y_train_tmp)
y_test=np.concatenate(y_test_tmp)
del X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp

mean=X_train.mean()
std=X_train.std()
X_train=(X_train-mean)/std
X_test=(X_test-mean)/std

# save dataset to numpy. too large to save it to npy.
#dataset={}
#dataset['X_train']=X_train
#dataset['X_test']=X_test
#dataset['y_train']=y_train
#dataset['y_test']=y_test
#filename=output_dir+'dataset.npy'
#np.save(filename, dataset)  # can't be saved because: OverflowError: cannot serialize a bytes object larger than 4 GiB

filename=output_dir+'dataset_10chn.hdf5'
f1 = h5py.File(filename, "w")
ds1 = f1.create_dataset("X_train",data=X_train)
ds2 = f1.create_dataset("X_test", data=X_test)
ds3 = f1.create_dataset("y_train", data=y_train)
ds4 = f1.create_dataset("y_test",data=y_test)
f1.close()

'''
## test
sid = 10  # 4
data_dir = data_dir + 'preprocessing/P' + str(sid) + '/tfInput/'
filename=data_dir+'dataset_10chn.hdf5'
f1 = h5py.File(filename, "r")
list(f1.keys())
X_train = f1['X_train'][:] # (650, 10, 148, 250)
X_test = f1['X_test'][:] #(50, 10, 148, 250)
y_train = f1['y_train'][:] # (650,)
y_test = f1['y_test'][:]
f1.close()
'''

