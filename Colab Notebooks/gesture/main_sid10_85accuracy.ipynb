{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_sid10_85accuracy.ipynb","provenance":[{"file_id":"1EYz0RDU00kpyR70LFTuucwD2tc_ry_fQ","timestamp":1618074355729}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1chE38v0xUsCRQF-8xoGQm2DdkomqgDtd","authorship_tag":"ABX9TyOZc0d3UzPkEMUCxTg0j6oC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CL_MTaBMQ9-p","executionInfo":{"status":"ok","timestamp":1631166919322,"user_tz":-480,"elapsed":547,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"2c18dd0f-6705-4ed5-b58a-c71924dd8b85"},"source":["%cd /content/drive/MyDrive/\n","# raw_data is imported from global config"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","metadata":{"id":"xwROBJfQRAYe"},"source":["%%capture\n","! pip install hdf5storage\n","! pip install mne==0.23.0\n","! pip install torch\n","! pip install tensorflow-gpu == 1.12.0\n","! pip install Braindecode==0.5.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NQVV2AYNaLO"},"source":["***Copy and Paste your code below.***"]},{"cell_type":"code","metadata":{"id":"W2RjuTz5T_ez"},"source":["import os, re\n","import hdf5storage\n","import numpy as np\n","from scipy.io import savemat\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","from braindecode.datautil import (create_from_mne_raw, create_from_mne_epochs)\n","import torch\n","from braindecode.util import set_random_seeds\n","from skorch.callbacks import LRScheduler\n","from skorch.helper import predefined_split\n","from braindecode import EEGClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","from braindecode.models import ShallowFBCSPNet,EEGNetv4,Deep4Net\n","from gesture.models.deepmodel import deepnet,deepnet_resnet\n","from gesture.models.EEGModels import DeepConvNet_210519_512_10\n","from gesture.models.tsception import TSception\n","\n","from gesture.myskorch import on_epoch_begin_callback, on_batch_end_callback\n","from gesture.config import *\n","from gesture.preprocess.chn_settings import get_channel_setting\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9or620gc2Bk"},"source":["import inspect as i\n","import sys\n","sys.stdout.write(i.getsource(deepnet))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Svy7ABlg3wuE"},"source":["pn=10 #4\n","Session_num,UseChn,EmgChn,TrigChn, activeChn = get_channel_setting(pn)\n","#fs=[Frequencies[i,1] for i in range(Frequencies.shape[0]) if Frequencies[i,0] == pn][0]\n","fs=1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_np8cCh3reZN","executionInfo":{"status":"ok","timestamp":1631166932067,"user_tz":-480,"elapsed":13,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"914bd779-87ba-4e72-fa05-6a2c621f727c"},"source":["[Frequencies[i,1] for i in range(Frequencies.shape[0]) if Frequencies[i,0] == pn][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"1LBbiAuvUVb_"},"source":["loadPath = data_dir+'preprocessing'+'/P'+str(pn)+'/preprocessing2.mat'\n","mat=hdf5storage.loadmat(loadPath)\n","data = mat['Datacell']\n","channelNum=int(mat['channelNum'][0,0])\n","data=np.concatenate((data[0,0],data[0,1]),0)\n","del mat\n","# standardization\n","# no effect. why?\n","chn_data=data[:,-3:]\n","data=data[:,:-3]\n","scaler = StandardScaler()\n","scaler.fit(data)\n","data=scaler.transform((data))\n","data=np.concatenate((data,chn_data),axis=1)\n","\n","# stim0 is trigger channel, stim1 is trigger position calculated from EMG signal.\n","chn_names=np.append([\"seeg\"]*len(UseChn),[\"stim0\", \"emg\",\"stim1\"])\n","chn_types=np.append([\"seeg\"]*len(UseChn),[\"stim\", \"emg\",\"stim\"])\n","info = mne.create_info(ch_names=list(chn_names), ch_types=list(chn_types), sfreq=fs)\n","raw = mne.io.RawArray(data.transpose(), info)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NxbH3k2Ej3SF"},"source":["# gesture/events type: 1,2,3,4,5\n","events0 = mne.find_events(raw, stim_channel='stim0')\n","events1 = mne.find_events(raw, stim_channel='stim1')\n","# events number should start from 0: 0,1,2,3,4, instead of 1,2,3,4,5\n","events0=events0-[0,0,1]\n","events1=events1-[0,0,1]\n","\n","#print(events[:5])  # show the first 5\n","# Epoch from 4s before(idle) until 4s after(movement) stim1.\n","raw=raw.pick([\"seeg\"])\n","epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)\n","# or epoch from 0s to 4s which only contain movement data.\n","# epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)\n","\n","epoch1=epochs['0'] # 20 trials. 8001 time points per trial for 8s.\n","epoch2=epochs['1']\n","epoch3=epochs['2']\n","epoch4=epochs['3']\n","epoch5=epochs['4']\n","list_of_epochs=[epoch1,epoch2,epoch3,epoch4,epoch5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edBaRd88j-DC"},"source":["#note: windows_datasets is of class BaseConcatDataset. windows_datasets.datasets is a list of all\n","# trials (like an epoch but organized as a list) epoched from a run.\n","#windows_datasets.datasets[0].windows is an epoch again created by a sliding window from one trial.\n","\n","\n","# 20 trials/epoch * 5 epochs =100 trials=100 datasets\n","# 1 dataset can be slided into ~161(depends on wind_size and stride) windows.\n","windows_datasets = create_from_mne_epochs(\n","    list_of_epochs,\n","    window_size_samples=500,\n","    window_stride_samples=250,\n","    drop_last_window=False\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WniFNShFkQwJ"},"source":["# train/valid/test split based on description column\n","desc=windows_datasets.description\n","desc=desc.rename(columns={0: 'split'})\n","trials_per_epoch=epoch1.events.shape[0] # 20 trial per epoch list/class\n","import random\n","val_test_num=2 # two val and two test trials\n","random_index = random.sample(range(trials_per_epoch), val_test_num*2)\n","sorted(random_index)\n","val_index=[rand+iclass*20 for iclass in range(5) for rand in sorted(random_index[:2]) ]\n","test_index=[rand+iclass*20 for iclass in range(5) for rand in sorted(random_index[-2:])]\n","train_index=[item for  item in list(range(100)) if item not in val_index+test_index]\n","desc.iloc[val_index]='validate'\n","desc.iloc[test_index]='test'\n","desc.iloc[train_index]='train'\n","# make sure there are val_test_num trials from each epoch (5 intotal) for both validate and test dataset\n","assert desc[desc['split'] == 'validate'].size == desc[desc['split'] == 'test'].size == val_test_num*5\n","windows_datasets.description=desc\n","splitted = windows_datasets.split('split')\n","\n","train_set = splitted['train']\n","valid_set = splitted['validate']\n","test_set = splitted['test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIIBAOLXkY2k"},"source":["cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n","device = 'cuda' if cuda else 'cpu'\n","if cuda:\n","    torch.backends.cudnn.benchmark = True\n","seed = 20200220  # random seed to make results reproducible\n","# Set random seed to be able to reproduce results\n","set_random_seeds(seed=seed, cuda=cuda)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nSrQqFFGkeK-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631166953813,"user_tz":-480,"elapsed":2861,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"d3a820b8-7046-47d0-c580-baf2f4b757a9"},"source":["n_classes = 5\n","# Extract number of chans and time steps from dataset\n","one_window=windows_datasets.datasets[0].windows.get_data()\n","n_chans = one_window.shape[1]\n","input_window_samples = one_window.shape[2]\n","\n","#model = ShallowFBCSPNet(n_chans,n_classes,input_window_samples=input_window_samples,final_conv_length='auto',) # 51%\n","#model = EEGNetv4(n_chans,n_classes,input_window_samples=input_window_samples,final_conv_length='auto',)\n","#model = deepnet(n_chans,n_classes,input_window_samples=input_window_samples,final_conv_length='auto',)\n","model = deepnet(n_chans,n_classes,input_window_samples=input_window_samples,final_conv_length='auto',) #87%\n","\n","#expand=True/False with 4 blocks: 69%; no block 4(conv_channels=all64):78% ; no block 4(conv_channels=64,50505050):76%\n","#model = deepnet_resnet(n_chans,n_classes,input_window_samples=input_window_samples,expand=False) \n","\n","\n","#model=TSception(1000,n_chans,3,3,0.5)\n","# Send model to GPU\n","if cuda:\n","    model.cuda()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"code","metadata":{"id":"bDqnhvuURw59"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"icHBaZeXkn85"},"source":["# These values we found good for shallow network:\n","lr = 0.0001\n","weight_decay = 1e-10\n","batch_size = 32\n","n_epochs = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cJpa6_TZkLg"},"source":["location=os.getcwd()\n","if re.compile('/Users/long/').match(location):\n","    my_callbacks=[\n","        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n","        ('on_epoch_begin_callback', on_epoch_begin_callback),('on_batch_end_callback',on_batch_end_callback),\n","    ]\n","elif re.compile('/content/drive').match(location):\n","   my_callbacks=[\n","        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n","    ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uf5hmYVAkr9i"},"source":["clf = EEGClassifier(\n","    model,\n","    criterion=torch.nn.NLLLoss,  #torch.nn.NLLLoss/CrossEntropyLoss\n","    optimizer=torch.optim.Adam, #optimizer=torch.optim.AdamW,\n","    train_split=predefined_split(valid_set),  # using valid_set for validation; None means no validate:both train and test on training dataset.\n","    optimizer__lr=lr,\n","    optimizer__weight_decay=weight_decay,\n","    batch_size=batch_size,\n","    callbacks=my_callbacks,\n","    device=device,\n",")\n","# Model training for a specified number of epochs. `y` is None as it is already supplied\n","# in the dataset.\n","clf.fit(train_set, y=None, epochs=n_epochs)"],"execution_count":null,"outputs":[]}]}