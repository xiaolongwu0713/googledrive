{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TSceptionBandInput.ipynb","provenance":[{"file_id":"1EYz0RDU00kpyR70LFTuucwD2tc_ry_fQ","timestamp":1618074355729}],"machine_shape":"hm","mount_file_id":"1MWzJBL19OlSV7mf1T91V5AMZNPLCegLe","authorship_tag":"ABX9TyNYwW4yAbK7w1xqWm9z7Ziv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CL_MTaBMQ9-p","executionInfo":{"status":"ok","timestamp":1618960427585,"user_tz":-60,"elapsed":608,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"39322e3e-0eca-4a64-f3be-8433bdd985c3"},"source":["%cd /content/drive/MyDrive/\n","# raw_data is imported from global config\n","root_dir='/content/drive/MyDrive/'  # ChangeThis\n","result_dir=root_dir+'grasp/TSception/result_test_dropout/'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fiU4GcMWzaFT","executionInfo":{"status":"ok","timestamp":1618960427958,"user_tz":-60,"elapsed":960,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import sys, importlib\n","#importlib.reload(sys.modules['grasp.config'])\n","from grasp.config import data_dir\n","# orveride the data_dir in config file\n","#data_dir='/content/drive/MyDrive/data/' # googleDrive"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"N4zjc3vuPTZJ","executionInfo":{"status":"ok","timestamp":1618960427961,"user_tz":-60,"elapsed":948,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"c881b9e2-9647-45f5-c67d-f745575a15c4"},"source":["data_dir"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/data/'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwROBJfQRAYe","executionInfo":{"status":"ok","timestamp":1618960432746,"user_tz":-60,"elapsed":5723,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"a78e8b9d-8af2-421c-d533-1f627a8b7007"},"source":["! pip install mne==0.19.2;\n","! pip install torch;"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mne==0.19.2 in /usr/local/lib/python3.7/dist-packages (0.19.2)\n","Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mne==0.19.2) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from mne==0.19.2) (1.19.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BQOkCPEnRJ7G","executionInfo":{"status":"ok","timestamp":1618960434039,"user_tz":-60,"elapsed":7006,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import DataLoader\n","\n","from grasp.TSception.utils import regulization\n","from grasp.utils import SEEGDataset,SEEGDataset1\n","from grasp.TSception.Models import TSception\n","\n","# load the data: regression to target force derivative\n","from grasp.utils import rawData2\n","from grasp.config import activeChannels, root_dir\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"O01RtPYIVdvd","executionInfo":{"status":"ok","timestamp":1618960434039,"user_tz":-60,"elapsed":6995,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["# reload function\n","import sys, importlib\n","importlib.reload(sys.modules['grasp.TSception.Models'])\n","importlib.reload(sys.modules['grasp.utils'])\n","\n","from grasp.utils import SEEGDataset,SEEGDataset1\n","from grasp.TSception.Models import TSception,TSception2\n","from grasp.utils import rawData2"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppXUCroiY2iC","executionInfo":{"status":"ok","timestamp":1618960434040,"user_tz":-60,"elapsed":6991,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["# import from another folder\n","import sys\n","sys.path.insert(1, '/content/drive/MyDrive/examples')\n","from IMV_LSTM.networks import IMVTensorLSTM"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Dt_Bz4ztzear","executionInfo":{"status":"ok","timestamp":1618960434041,"user_tz":-60,"elapsed":6968,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"a0e897bc-c949-4ea4-d36f-efe745bfa233"},"source":["data_dir"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/data/'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"1IjnSRE7WSZt","executionInfo":{"status":"ok","timestamp":1618960434041,"user_tz":-60,"elapsed":6960,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import inspect as i\n","import sys\n","#sys.stdout.write(i.getsource(rawData2));"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BjdQBwjTddA","executionInfo":{"status":"ok","timestamp":1618960434042,"user_tz":-60,"elapsed":6953,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"e9ef09eb-e122-4a2f-cf5f-8fcd2d1aa04f"},"source":["enable_cuda = torch.cuda.is_available()\n","print('GPU computing: ', enable_cuda)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["GPU computing:  True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VRvPvrrXZaOv","executionInfo":{"status":"ok","timestamp":1618960442610,"user_tz":-60,"elapsed":15510,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["%%capture\n","# suppress the output\n","sampling_rate=1000\n","#traindata, valdata, testdata = rawData2('raw',activeChannels,move2=False)  # (chns, 15000/15001, 118) (channels, time, trials)\n","traindata, valdata, testdata = rawData2('band','all',move2=True)\n","traindata = traindata.transpose(2, 0, 1)  # (118, 20, 15000) (trials,channels,  time)\n","valdata = valdata.transpose(2, 0, 1) # (8, 20, 15000)\n","testdata = testdata.transpose(2, 0, 1)  # (8, 20, 15000)\n","trainx_ds, trainy_ds = traindata[:, :-2, :], traindata[:, -2, :] #-2 is real force, -1 is target\n","valx_ds, valy_ds = valdata[:, :-2, :], valdata[:, -2, :]\n","testx_ds, testy_ds = testdata[:, :-2, :], testdata[:, -2, :]\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DX0sWI8Bc4zG","executionInfo":{"status":"ok","timestamp":1618960442611,"user_tz":-60,"elapsed":15503,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["chnNum=trainx_ds.shape[1]\n","learning_rate=0.002\n","epochs=100\n","step=50 #ms\n","T=1000 #ms\n","totalLen=trainx_ds.shape[2] #ms\n","batch_size=int((totalLen-T)/step) # 280\n","num_T = 3 # (6 conv2d layers) * ( 3 kernel each layer)\n","num_S = 3\n","hidden_size=222\n","dropout=0.2\n","Lambda = 1e-6\n","\n","dataset_train = SEEGDataset1(trainx_ds, trainy_ds,T,step)\n","dataset_val = SEEGDataset1(valx_ds, valy_ds,T,step)\n","dataset_test = SEEGDataset1(testx_ds, testy_ds,T,step)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMFsvnRJhExd","executionInfo":{"status":"ok","timestamp":1618960442612,"user_tz":-60,"elapsed":15489,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"bccb0e10-6361-4859-f5d4-a041a4b41461"},"source":["len(dataset_train)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["118"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"FjOmhndXNFUi","executionInfo":{"status":"ok","timestamp":1618960463173,"user_tz":-60,"elapsed":673,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["#trainy.shape\n","#plt.plot(trainy_ds[0,:])"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CIQaf0N63aE","executionInfo":{"status":"ok","timestamp":1618960463522,"user_tz":-60,"elapsed":1012,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["train_loader = DataLoader(dataset=dataset_train, batch_size=1, shuffle=True, pin_memory=False)\n","val_loader = DataLoader(dataset=dataset_val, batch_size=1, pin_memory=False)\n","test_loader = DataLoader(dataset=dataset_test, batch_size=1, pin_memory=False)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bYgehRWw3YY","executionInfo":{"status":"ok","timestamp":1618960466556,"user_tz":-60,"elapsed":4041,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["# __init__(self,input_size, sampling_rate, num_T, num_S, hiden, dropout_rate)\n","net = TSception2(chnNum,sampling_rate, num_T, num_S,batch_size).float()\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","if(enable_cuda):\n","\tnet.cuda()\n"," \n","#checkpoint = torch.load(result_dir+'checkpoint95.pth')\n","#net.load_state_dict(checkpoint['state_dict'])\n","#optimizer.load_state_dict(checkpoint['optimizer'])"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"124r0ZZh94K8","executionInfo":{"status":"ok","timestamp":1618973143472,"user_tz":-60,"elapsed":12680951,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"c9500871-3d80-4f1c-f6e6-5b90b56f4e65"},"source":["debugg=False\n","#debugg=True\n","for epoch in range(200):\n","    print(\"------ epoch \" + str(epoch) + \" -----\")\n","    net.train()\n","\n","    loss_epoch=0\n","    #trial=0\n","    for trial, (trainx, trainy) in enumerate(train_loader): # ([1, 15000, 19]), ([1, 15000])\n","        #trainy[0,-1]+=0.05\n","        if debugg==True: # just test one trial\n","            if trial == 1:\n","                break\n","                pass\n","        optimizer.zero_grad()\n","        \n","        if (enable_cuda):\n","            x= trainx.float().cuda()\n","            target = trainy.float().cuda()\n","        y_pred = net(x)\n","        #target = torch.from_numpy(target)\n","\n","        # regularization\n","        loss1 = criterion(y_pred, target.float())\n","        loss2 = regulization(net, Lambda)\n","        #loss3 = y_pred.cpu().detach().numpy()\n","        #loss3 = np.std(np.diff(loss3.reshape(-1)))\n","        loss=loss1+loss2 #+loss3*0.001\n","        loss.backward()\n","        optimizer.step()\n","\n","        ls=loss1.item()\n","        loss_epoch+=ls\n","        with open(result_dir+ \"trainlose.txt\", \"a\") as f:\n","            f.write(str(loss1) + \"\\n\")\n","    print(\"\"+str(epoch)+\" loss:\"+str(loss_epoch/(trial+1))+\".\")\n","    if epoch % 1 ==0:\n","        net.eval()\n","        print(\"Validating...\")\n","        with torch.no_grad():\n","            vpredAll = []\n","            vtargetAll = []\n","            for trial, (vx, vtarget) in enumerate(val_loader):  # ([1, 15000, 19]), ([1, 15000])                \n","                if (enable_cuda):\n","                    vx= vx.float().cuda()\n","                    vtarget = vtarget.float().cuda()\n","                y_pred = net(vx)\n","                loss3 = criterion(y_pred.squeeze(), vtarget.squeeze())\n","                with open(result_dir+\"testlose.txt\", \"a\") as f:\n","                    f.write(str(loss3) + \"\\n\")\n","\n","                y_pred=y_pred.squeeze().cpu().detach().numpy()\n","                vtarget=vtarget.squeeze().cpu().numpy()\n","                vpredAll.append(y_pred)\n","                vtargetAll.append(vtarget)\n","\n","\n","        vpredAll = np.concatenate(vpredAll,axis=0)\n","        vtargetAll = np.concatenate(vtargetAll, axis=0)\n","\n","        fig, ax = plt.subplots(figsize=(6, 3))\n","        plt.ion()\n","        ax.clear()\n","        ax.plot(vtargetAll, label=\"True\", linewidth=1)\n","        ax.plot(vpredAll, label='Predicted - Test', linewidth=1)\n","        ax.legend(loc='upper left')\n","        figname = result_dir+'prediction' + str(epoch) + '.png'\n","        fig.savefig(figname)\n","        plt.close(fig)\n","    if epoch % 5==0:\n","        state = {\n","            'state_dict': net.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","        }\n","        savepath = result_dir+'checkpoint'+str(epoch)+'.pth'\n","        torch.save(state, savepath)\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["------ epoch 0 -----\n","0 loss:0.10600744359889779.\n","Validating...\n","------ epoch 1 -----\n","1 loss:0.09814209513902916.\n","Validating...\n","------ epoch 2 -----\n","2 loss:0.09730977440347612.\n","Validating...\n","------ epoch 3 -----\n","3 loss:0.096645340978531.\n","Validating...\n","------ epoch 4 -----\n","4 loss:0.09577996006740605.\n","Validating...\n","------ epoch 5 -----\n","5 loss:0.09503414010692199.\n","Validating...\n","------ epoch 6 -----\n","6 loss:0.09587872843652712.\n","Validating...\n","------ epoch 7 -----\n","7 loss:0.09462108038428982.\n","Validating...\n","------ epoch 8 -----\n","8 loss:0.09343788438176705.\n","Validating...\n","------ epoch 9 -----\n","9 loss:0.09289797312201206.\n","Validating...\n","------ epoch 10 -----\n","10 loss:0.09147082908094813.\n","Validating...\n","------ epoch 11 -----\n","11 loss:0.08854889582400605.\n","Validating...\n","------ epoch 12 -----\n","12 loss:0.08802078611422647.\n","Validating...\n","------ epoch 13 -----\n","13 loss:0.08809828579867796.\n","Validating...\n","------ epoch 14 -----\n","14 loss:0.08732186911343517.\n","Validating...\n","------ epoch 15 -----\n","15 loss:0.08646817476946418.\n","Validating...\n","------ epoch 16 -----\n","16 loss:0.0848263665812753.\n","Validating...\n","------ epoch 17 -----\n","17 loss:0.08685623309022542.\n","Validating...\n","------ epoch 18 -----\n","18 loss:0.08686264012387748.\n","Validating...\n","------ epoch 19 -----\n","19 loss:0.09281767110766495.\n","Validating...\n","------ epoch 20 -----\n","20 loss:0.09261587542339654.\n","Validating...\n","------ epoch 21 -----\n","21 loss:0.09177045599099691.\n","Validating...\n","------ epoch 22 -----\n","22 loss:0.09224025656516521.\n","Validating...\n","------ epoch 23 -----\n","23 loss:0.08827435983723755.\n","Validating...\n","------ epoch 24 -----\n","24 loss:0.08688153003705508.\n","Validating...\n","------ epoch 25 -----\n","25 loss:0.08639765005969142.\n","Validating...\n","------ epoch 26 -----\n","26 loss:0.08574734977841125.\n","Validating...\n","------ epoch 27 -----\n","27 loss:0.08334309429372266.\n","Validating...\n","------ epoch 28 -----\n","28 loss:0.08357643503380024.\n","Validating...\n","------ epoch 29 -----\n","29 loss:0.08103582482406144.\n","Validating...\n","------ epoch 30 -----\n","30 loss:0.08036249400889975.\n","Validating...\n","------ epoch 31 -----\n","31 loss:0.08084703729314319.\n","Validating...\n","------ epoch 32 -----\n","32 loss:0.07895475869082798.\n","Validating...\n","------ epoch 33 -----\n","33 loss:0.08813444279150058.\n","Validating...\n","------ epoch 34 -----\n","34 loss:0.09630659363879743.\n","Validating...\n","------ epoch 35 -----\n","35 loss:0.09628357034239729.\n","Validating...\n","------ epoch 36 -----\n","36 loss:0.09581951531818357.\n","Validating...\n","------ epoch 37 -----\n","37 loss:0.09207239057237314.\n","Validating...\n","------ epoch 38 -----\n","38 loss:0.09007875227479864.\n","Validating...\n","------ epoch 39 -----\n","39 loss:0.08930183708730896.\n","Validating...\n","------ epoch 40 -----\n","40 loss:0.08951668648080806.\n","Validating...\n","------ epoch 41 -----\n","41 loss:0.09088000935360284.\n","Validating...\n","------ epoch 42 -----\n","42 loss:0.08894197337360958.\n","Validating...\n","------ epoch 43 -----\n","43 loss:0.08755768452755223.\n","Validating...\n","------ epoch 44 -----\n","44 loss:0.08572718544500106.\n","Validating...\n","------ epoch 45 -----\n","45 loss:0.08566048839997689.\n","Validating...\n","------ epoch 46 -----\n","46 loss:0.08533288458741065.\n","Validating...\n","------ epoch 47 -----\n","47 loss:0.084321399819169.\n","Validating...\n","------ epoch 48 -----\n","48 loss:0.08422404058845871.\n","Validating...\n","------ epoch 49 -----\n","49 loss:0.08280095709803498.\n","Validating...\n","------ epoch 50 -----\n","50 loss:0.08035465365402021.\n","Validating...\n","------ epoch 51 -----\n","51 loss:0.08069411798585523.\n","Validating...\n","------ epoch 52 -----\n","52 loss:0.08001885289263169.\n","Validating...\n","------ epoch 53 -----\n","53 loss:0.07690664743846756.\n","Validating...\n","------ epoch 54 -----\n","54 loss:0.07814505794953744.\n","Validating...\n","------ epoch 55 -----\n","55 loss:0.07540521619967737.\n","Validating...\n","------ epoch 56 -----\n","56 loss:0.0735368200388374.\n","Validating...\n","------ epoch 57 -----\n","57 loss:0.07122559403463946.\n","Validating...\n","------ epoch 58 -----\n","58 loss:0.06854708029462372.\n","Validating...\n","------ epoch 59 -----\n","59 loss:0.06977658309200305.\n","Validating...\n","------ epoch 60 -----\n","60 loss:0.06645198620192833.\n","Validating...\n","------ epoch 61 -----\n","61 loss:0.0681556293788224.\n","Validating...\n","------ epoch 62 -----\n","62 loss:0.06577682724001549.\n","Validating...\n","------ epoch 63 -----\n","63 loss:0.06951493167681462.\n","Validating...\n","------ epoch 64 -----\n","64 loss:0.0700647085036893.\n","Validating...\n","------ epoch 65 -----\n","65 loss:0.06633459343338165.\n","Validating...\n","------ epoch 66 -----\n","66 loss:0.06938732057904541.\n","Validating...\n","------ epoch 67 -----\n","67 loss:0.07478860955117113.\n","Validating...\n","------ epoch 68 -----\n","68 loss:0.0799663987452701.\n","Validating...\n","------ epoch 69 -----\n","69 loss:0.08140670797803391.\n","Validating...\n","------ epoch 70 -----\n","70 loss:0.08002937163652504.\n","Validating...\n","------ epoch 71 -----\n","71 loss:0.07581645943287571.\n","Validating...\n","------ epoch 72 -----\n","72 loss:0.07498999015759614.\n","Validating...\n","------ epoch 73 -----\n","73 loss:0.07589051936421606.\n","Validating...\n","------ epoch 74 -----\n","74 loss:0.08873038925230503.\n","Validating...\n","------ epoch 75 -----\n","75 loss:0.08526263841412078.\n","Validating...\n","------ epoch 76 -----\n","76 loss:0.0846179063408241.\n","Validating...\n","------ epoch 77 -----\n","77 loss:0.08362239639479983.\n","Validating...\n","------ epoch 78 -----\n","78 loss:0.08252173491706283.\n","Validating...\n","------ epoch 79 -----\n","79 loss:0.08616606300791442.\n","Validating...\n","------ epoch 80 -----\n","80 loss:0.07705428322650872.\n","Validating...\n","------ epoch 81 -----\n","81 loss:0.07454080053336792.\n","Validating...\n","------ epoch 82 -----\n","82 loss:0.07809774823076392.\n","Validating...\n","------ epoch 83 -----\n","83 loss:0.08179821767765334.\n","Validating...\n","------ epoch 84 -----\n","84 loss:0.0748960903166967.\n","Validating...\n","------ epoch 85 -----\n","85 loss:0.07442828837655864.\n","Validating...\n","------ epoch 86 -----\n","86 loss:0.0799058318311759.\n","Validating...\n","------ epoch 87 -----\n","87 loss:0.09084726456489603.\n","Validating...\n","------ epoch 88 -----\n","88 loss:0.08545503703782618.\n","Validating...\n","------ epoch 89 -----\n","89 loss:0.0856468293547504.\n","Validating...\n","------ epoch 90 -----\n","90 loss:0.07959275868705522.\n","Validating...\n","------ epoch 91 -----\n","91 loss:0.07850353392946013.\n","Validating...\n","------ epoch 92 -----\n","92 loss:0.07877854221516241.\n","Validating...\n","------ epoch 93 -----\n","93 loss:0.07296639154428396.\n","Validating...\n","------ epoch 94 -----\n","94 loss:0.07036235700045729.\n","Validating...\n","------ epoch 95 -----\n","95 loss:0.07064798983382219.\n","Validating...\n","------ epoch 96 -----\n","96 loss:0.07317622842551288.\n","Validating...\n","------ epoch 97 -----\n","97 loss:0.07151962358551889.\n","Validating...\n","------ epoch 98 -----\n","98 loss:0.06915145820417141.\n","Validating...\n","------ epoch 99 -----\n","99 loss:0.07060607235436722.\n","Validating...\n","------ epoch 100 -----\n","100 loss:0.06707820294709024.\n","Validating...\n","------ epoch 101 -----\n","101 loss:0.06739150192115013.\n","Validating...\n","------ epoch 102 -----\n","102 loss:0.06782580062084026.\n","Validating...\n","------ epoch 103 -----\n","103 loss:0.06487844502395493.\n","Validating...\n","------ epoch 104 -----\n","104 loss:0.06426389596693344.\n","Validating...\n","------ epoch 105 -----\n","105 loss:0.06482512091081273.\n","Validating...\n","------ epoch 106 -----\n","106 loss:0.06495259968185071.\n","Validating...\n","------ epoch 107 -----\n","107 loss:0.06482574260020155.\n","Validating...\n","------ epoch 108 -----\n","108 loss:0.06435803207963453.\n","Validating...\n","------ epoch 109 -----\n","109 loss:0.061703186821571346.\n","Validating...\n","------ epoch 110 -----\n","110 loss:0.06349051999464883.\n","Validating...\n","------ epoch 111 -----\n","111 loss:0.06112024628841397.\n","Validating...\n","------ epoch 112 -----\n","112 loss:0.06890095043453877.\n","Validating...\n","------ epoch 113 -----\n","113 loss:0.06598744353563604.\n","Validating...\n","------ epoch 114 -----\n","114 loss:0.06912712454085507.\n","Validating...\n","------ epoch 115 -----\n","115 loss:0.07937186697529534.\n","Validating...\n","------ epoch 116 -----\n","116 loss:0.07898175230218192.\n","Validating...\n","------ epoch 117 -----\n","117 loss:0.07287070067536275.\n","Validating...\n","------ epoch 118 -----\n","118 loss:0.07293872489451857.\n","Validating...\n","------ epoch 119 -----\n","119 loss:0.07470383341187391.\n","Validating...\n","------ epoch 120 -----\n","120 loss:0.07357044220444257.\n","Validating...\n","------ epoch 121 -----\n","121 loss:0.07482201003043329.\n","Validating...\n","------ epoch 122 -----\n","122 loss:0.07221331570486901.\n","Validating...\n","------ epoch 123 -----\n","123 loss:0.07083917672003982.\n","Validating...\n","------ epoch 124 -----\n","124 loss:0.06908388083832244.\n","Validating...\n","------ epoch 125 -----\n","125 loss:0.0715164184507172.\n","Validating...\n","------ epoch 126 -----\n","126 loss:0.07149914670262043.\n","Validating...\n","------ epoch 127 -----\n","127 loss:0.07148226172173933.\n","Validating...\n","------ epoch 128 -----\n","128 loss:0.07038484763953898.\n","Validating...\n","------ epoch 129 -----\n","129 loss:0.06910339169898781.\n","Validating...\n","------ epoch 130 -----\n","130 loss:0.071010458977672.\n","Validating...\n","------ epoch 131 -----\n","131 loss:0.0646326302913791.\n","Validating...\n","------ epoch 132 -----\n","132 loss:0.06484020998606742.\n","Validating...\n","------ epoch 133 -----\n","133 loss:0.06525200314156837.\n","Validating...\n","------ epoch 134 -----\n","134 loss:0.06077507128386553.\n","Validating...\n","------ epoch 135 -----\n","135 loss:0.06342335417866707.\n","Validating...\n","------ epoch 136 -----\n","136 loss:0.06184087871273948.\n","Validating...\n","------ epoch 137 -----\n","137 loss:0.05987694183111948.\n","Validating...\n","------ epoch 138 -----\n","138 loss:0.05828227352161529.\n","Validating...\n","------ epoch 139 -----\n","139 loss:0.05648215802512684.\n","Validating...\n","------ epoch 140 -----\n","140 loss:0.05945745161813447.\n","Validating...\n","------ epoch 141 -----\n","141 loss:0.05783782076185285.\n","Validating...\n","------ epoch 142 -----\n","142 loss:0.05648893102908791.\n","Validating...\n","------ epoch 143 -----\n","143 loss:0.05993752565108618.\n","Validating...\n","------ epoch 144 -----\n","144 loss:0.06085500215827409.\n","Validating...\n","------ epoch 145 -----\n","145 loss:0.05923875387347603.\n","Validating...\n","------ epoch 146 -----\n","146 loss:0.062066565867576556.\n","Validating...\n","------ epoch 147 -----\n","147 loss:0.06887298193365587.\n","Validating...\n","------ epoch 148 -----\n","148 loss:0.06688270028049158.\n","Validating...\n","------ epoch 149 -----\n","149 loss:0.06352218945305478.\n","Validating...\n","------ epoch 150 -----\n","150 loss:0.0592676534641029.\n","Validating...\n","------ epoch 151 -----\n","151 loss:0.06001717265758474.\n","Validating...\n","------ epoch 152 -----\n","152 loss:0.05839537717875535.\n","Validating...\n","------ epoch 153 -----\n","153 loss:0.05655673290681788.\n","Validating...\n","------ epoch 154 -----\n","154 loss:0.057677551046392675.\n","Validating...\n","------ epoch 155 -----\n","155 loss:0.057164449410481474.\n","Validating...\n","------ epoch 156 -----\n","156 loss:0.05923333082158687.\n","Validating...\n","------ epoch 157 -----\n","157 loss:0.06483171917340261.\n","Validating...\n","------ epoch 158 -----\n","158 loss:0.0754305408178371.\n","Validating...\n","------ epoch 159 -----\n","159 loss:0.06315012412713998.\n","Validating...\n","------ epoch 160 -----\n","160 loss:0.061693989111394704.\n","Validating...\n","------ epoch 161 -----\n","161 loss:0.06206285111385129.\n","Validating...\n","------ epoch 162 -----\n","162 loss:0.061073363371887956.\n","Validating...\n","------ epoch 163 -----\n","163 loss:0.05850851102100717.\n","Validating...\n","------ epoch 164 -----\n","164 loss:0.058332493844426285.\n","Validating...\n","------ epoch 165 -----\n","165 loss:0.05910445574544749.\n","Validating...\n","------ epoch 166 -----\n","166 loss:0.056320403134292464.\n","Validating...\n","------ epoch 167 -----\n","167 loss:0.054908403775544234.\n","Validating...\n","------ epoch 168 -----\n","168 loss:0.054705301741674796.\n","Validating...\n","------ epoch 169 -----\n","169 loss:0.053748004130577134.\n","Validating...\n","------ epoch 170 -----\n","170 loss:0.051751330451471574.\n","Validating...\n","------ epoch 171 -----\n","171 loss:0.057792238228149335.\n","Validating...\n","------ epoch 172 -----\n","172 loss:0.052239483459142304.\n","Validating...\n","------ epoch 173 -----\n","173 loss:0.05208580857300657.\n","Validating...\n","------ epoch 174 -----\n","174 loss:0.05229464250664085.\n","Validating...\n","------ epoch 175 -----\n","175 loss:0.05094607584415225.\n","Validating...\n","------ epoch 176 -----\n","176 loss:0.05215080216984754.\n","Validating...\n","------ epoch 177 -----\n","177 loss:0.053850193949952975.\n","Validating...\n","------ epoch 178 -----\n","178 loss:0.050339592537858475.\n","Validating...\n","------ epoch 179 -----\n","179 loss:0.04968359274789691.\n","Validating...\n","------ epoch 180 -----\n","180 loss:0.046342150663357166.\n","Validating...\n","------ epoch 181 -----\n","181 loss:0.04845966359253152.\n","Validating...\n","------ epoch 182 -----\n","182 loss:0.04706485550534927.\n","Validating...\n","------ epoch 183 -----\n","183 loss:0.048603970360137146.\n","Validating...\n","------ epoch 184 -----\n","184 loss:0.0505240914624942.\n","Validating...\n","------ epoch 185 -----\n","185 loss:0.046719741439288955.\n","Validating...\n","------ epoch 186 -----\n","186 loss:0.04944155073598406.\n","Validating...\n","------ epoch 187 -----\n","187 loss:0.04690755510671159.\n","Validating...\n","------ epoch 188 -----\n","188 loss:0.04845482910493926.\n","Validating...\n","------ epoch 189 -----\n","189 loss:0.05138340465314055.\n","Validating...\n","------ epoch 190 -----\n","190 loss:0.04996188140426904.\n","Validating...\n","------ epoch 191 -----\n","191 loss:0.04965026253613375.\n","Validating...\n","------ epoch 192 -----\n","192 loss:0.0479887089913048.\n","Validating...\n","------ epoch 193 -----\n","193 loss:0.05025363149579173.\n","Validating...\n","------ epoch 194 -----\n","194 loss:0.04933258513051827.\n","Validating...\n","------ epoch 195 -----\n","195 loss:0.04909709108582998.\n","Validating...\n","------ epoch 196 -----\n","196 loss:0.04635801397548136.\n","Validating...\n","------ epoch 197 -----\n","197 loss:0.04861715048456849.\n","Validating...\n","------ epoch 198 -----\n","198 loss:0.04918289570122073.\n","Validating...\n","------ epoch 199 -----\n","199 loss:0.04923697162451128.\n","Validating...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G9Ml_yK3Wvpp","executionInfo":{"status":"ok","timestamp":1618973143473,"user_tz":-60,"elapsed":12680947,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":[""],"execution_count":19,"outputs":[]}]}