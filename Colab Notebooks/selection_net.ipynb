{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"selection_net.ipynb","provenance":[{"file_id":"1EYz0RDU00kpyR70LFTuucwD2tc_ry_fQ","timestamp":1618074355729}],"machine_shape":"hm","mount_file_id":"107-96-H-9eVoAjmrBQe3sMCDxRv6Ig3m","authorship_tag":"ABX9TyOGaAJmGU09qBjQXmJs0Bz6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"p2R6UFNgi7Nr"},"source":["# not matter is small or big TSception network, selection_net(including selection_layer and TSception) doesn't converge to miminum. \n","# Maybe regression is not the right job."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRCmcYSt9wqh","executionInfo":{"status":"ok","timestamp":1624629833008,"user_tz":-60,"elapsed":187,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"16af3035-cc58-4644-8fe2-ac7ce66c7466"},"source":["%cd /content/drive/MyDrive/\n","# raw_data is imported from global config"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pznHHra4_aOg","executionInfo":{"status":"ok","timestamp":1624629839082,"user_tz":-60,"elapsed":5851,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["%%capture\n","! pip install mne==0.19.2;\n","! pip install torch==1.7.0;"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJxokHgH95AS","executionInfo":{"status":"ok","timestamp":1624629840669,"user_tz":-60,"elapsed":1592,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import DataLoader\n","from grasp.TSception.utils import regulization\n","from grasp.utils import SEEGDataset, load_data, SEEGDataset3D, cuda_or_cup, set_random_seeds\n","from grasp.TSception.Models import TSception2,selection_net\n","from grasp.braindecode.Models import shallowConv,deepConv\n","from grasp.process.channel_settings import badtrials\n","from grasp.config import root_dir"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyEOXTXgHlc4","executionInfo":{"status":"ok","timestamp":1624629840673,"user_tz":-60,"elapsed":11,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import sys, importlib\n","importlib.reload(sys.modules['grasp.TSception.Models'])\n","from grasp.TSception.Models import TSception2,selection_net,SelectionLayer"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHeYjqDCJ57K","executionInfo":{"status":"ok","timestamp":1624629840674,"user_tz":-60,"elapsed":11,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import inspect as i\n","import sys\n","#sys.stdout.write(i.getsource(SelectionLayer))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgdufZcJ960w","executionInfo":{"status":"ok","timestamp":1624629840674,"user_tz":-60,"elapsed":10,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"1494d09f-e38b-4ffd-abb5-79d14849c2ba"},"source":["device=cuda_or_cup()\n","enable_cuda = torch.cuda.is_available()\n","print('GPU computing: ', enable_cuda)\n","seed = 123456789  # random seed to make results reproducible\n","# Set random seed to be able to reproduce results\n","set_random_seeds(seed=seed)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["GPU computing:   True\n","GPU computing:  True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h3nGSPVo-F1W","executionInfo":{"status":"ok","timestamp":1624629840675,"user_tz":-60,"elapsed":9,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["sid=10 # 10 converge faster\n","optins=['normalized_frequency_and_raw','frequency_and_raw','raw']\n","input=optins[2]\n","\n","#result_dir=root_dir+'grasp/TSception/shallowConv'+str(sid)+'/'\n","result_dir=root_dir+'grasp/TSception/result_TSSmall'+'_'+input+str(sid)+'/'\n","saved_numpy=result_dir+'result/'\n","pths=result_dir+'pth/'\n","pro_dir=result_dir + '/probs/'\n","\n","import os\n","if not os.path.exists(result_dir):\n","    os.makedirs(result_dir)\n","if not os.path.exists(saved_numpy):\n","    os.makedirs(saved_numpy)\n","if not os.path.exists(pths):\n","    os.makedirs(pths)\n","if not os.path.exists(pro_dir):\n","    os.makedirs(pro_dir)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5g2PPSlO-IxJ","executionInfo":{"status":"ok","timestamp":1624629851156,"user_tz":-60,"elapsed":10489,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["%%capture\n","# suppress the output\n","traindata, valdata, testdata = load_data(sid,split=True,move2=True,input=input)\n","traindata = traindata.transpose(2, 0, 1)  #-->(trials94,channels,  time)\n","valdata = valdata.transpose(2, 0, 1) # 32\n","testdata = testdata.transpose(2, 0, 1)  # 8"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"P59dQr40-LQA","executionInfo":{"status":"ok","timestamp":1624629851160,"user_tz":-60,"elapsed":17,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["# Total trial number from train, val and test dataset should be equal to total trial from config file.\n","total_trials1=traindata.shape[0]+valdata.shape[0]+testdata.shape[0]\n","total_trials2=4*40-(len(badtrials[sid][0])+len(badtrials[sid][1])+len(badtrials[sid][2])+len(badtrials[sid][3]))\n","if total_trials1!=total_trials2:\n","    raise SystemExit(\"Trial number dones't match\")\n","trainx, trainy = traindata[:, :-2, :], traindata[:, -2, :] #-2 is real force, -1 is target\n","valx, valy = valdata[:, :-2, :], valdata[:, -2, :]\n","testx, testy = testdata[:, :-2, :], testdata[:, -2, :]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuLv2Qo4-Nap","executionInfo":{"status":"ok","timestamp":1624629851160,"user_tz":-60,"elapsed":16,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["if input=='normalized_frequency_and_raw':\n","    fs=250\n","    step=125\n","    T=250\n","else:\n","    fs=1000\n","    step=500 #ms\n","    T=1000 #ms\n","dataset_train = SEEGDataset3D(trainx, trainy,T,step)\n","dataset_val = SEEGDataset3D(valx, valy,T,step)\n","dataset_test = SEEGDataset3D(testx, testy,T,step)\n","train_loader = DataLoader(dataset=dataset_train, batch_size=1, shuffle=True, pin_memory=False)\n","val_loader = DataLoader(dataset=dataset_val, batch_size=1, pin_memory=False)\n","test_loader = DataLoader(dataset=dataset_test, batch_size=1, pin_memory=False)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"EtWoPea--Ulj","executionInfo":{"status":"ok","timestamp":1624629851161,"user_tz":-60,"elapsed":16,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["epochs=800\n","\n","# TSception parameter\n","sampling_rate=1000\n","learning_rate=0.002\n","totalLen=trainx.shape[2] #ms\n","batch_size=int((totalLen-T)/step) # 280\n","num_T = 3 # (6 conv2d layers) * ( 3 kernel each layer)\n","num_S = 3\n","hidden_size=222\n","dropout=0.5\n","#Lambda = 1e-10\n","\n","# braindecode parameter\n","checkshape=torch.squeeze(next(iter(test_loader))[0],dim=0) # torch.Size([28,1,102,1000])\n","length=checkshape.shape[3] # torch.Size([28, 102, 1000])\n","convfeature=40\n","tkernelSize=200\n","avgpoolKernel=100\n","maxpoolKernel=3\n","maxpoolStride=3\n","blockKernelSize=10\n","input_dim=checkshape.shape[2]\n","\n","# selection neuron\n","M=10"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8SqR8xA-hcY","executionInfo":{"status":"ok","timestamp":1624629851162,"user_tz":-60,"elapsed":16,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["#Create schedule for temperature and regularization threshold\n","#Create a vector of length epochs, decaying start_value to end_value exponentially, reaching end_value at end_epoch\n","\n","start_temp=20\n","end_temp=0.1\n","start_thresh=8.0\n","end_thresh=1.1\n","\n","def exponential_decay_schedule(start_value,end_value,epochs,end_epoch):\n","    t = torch.FloatTensor(torch.arange(0.0,epochs))\n","    p = torch.clamp(t/end_epoch,0,1)\n","    out = start_value*torch.pow(end_value/start_value,p)\n","    return out\n","\n","temperature_schedule = exponential_decay_schedule(start_temp,end_temp,epochs,int(epochs*3/4)) #one-hot degree\n","thresh_schedule = exponential_decay_schedule(start_thresh,end_thresh,epochs,epochs) # duplication penalty\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ce1cjQW_-er4","executionInfo":{"status":"ok","timestamp":1624629853752,"user_tz":-60,"elapsed":2606,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["#Network loss function\n","def loss_function(output,target,model,lamba,weight_decay):\n","    l = nn.MSELoss()\n","    sup_loss = l(output,target)\n","    reg = model.regularizer(lamba,weight_decay)\n","    return sup_loss,reg\n","\n","weight_decay=1e-6 #1e-6 # model parameter weight decay\n","lamba=0.1 # 0.1 regularization of penalization of duplication selection\n","\n","enable_select=True\n","# def __init__(self, input_dim, M ,sampling_rate, chnNum, num_T, num_S,dropout):\n","#Question: forward called during initialization throw error: RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n","#Git log: 36b198f7a49df375b8562f5d2d8c2bbef5dbbc61\n","#Solution1: find a PC with GPU to debug.\n","#Solution2: no need to call selection layer forward. Dimmension is determinant for selection layer.\n","shape=checkshape.shape # torch.Size([28,1,102,1000])\n","if enable_select==True:\n","    net = selection_net(shape,enable_select,input_dim, M, sampling_rate,M, num_T, num_S,dropout)\n","    net.enable_select = True\n","    net.set_freeze(False)\n","else:\n","    net = selection_net(shape,enable_select,input_dim, M, sampling_rate, input_dim, num_T, num_S, dropout)\n","    net.enable_select = False\n","\n","\n","if(enable_cuda):\n","    net.cuda()\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.Adagrad(net.parameters(), lr=learning_rate,weight_decay=1e-4)\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"In64_47aLH-U","executionInfo":{"status":"ok","timestamp":1624629853754,"user_tz":-60,"elapsed":7,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"b7a0f8a5-976f-4e50-8fdb-9bd1104530da"},"source":["torch.cuda.is_available()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"XoDEwAEB-fTQ","executionInfo":{"status":"ok","timestamp":1624629853755,"user_tz":-60,"elapsed":6,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["#checkpoint = torch.load(result_dir+'checkpoint440.pth')\n","#net.load_state_dict(checkpoint['net'])\n","#optimizer.load_state_dict(checkpoint['optimizer'])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"q0HifOa5-7Lo","executionInfo":{"status":"ok","timestamp":1624629854127,"user_tz":-60,"elapsed":377,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"4b4befcd-5286-44e0-b69a-242c3c38d747"},"source":["fig2, ax2=plt.subplots()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"s6W0vjF1--Iv","executionInfo":{"status":"error","timestamp":1624630847405,"user_tz":-60,"elapsed":993282,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"1a07dfdc-d6d4-4e9e-f8eb-e4adc43a6607"},"source":["debugg = False\n","#debugg=True\n","for epoch in range(epochs):\n","    print(\"------ epoch \" + str(epoch) + \" -----\")\n","    net.train()\n","    if enable_select==True:\n","        net.set_thresh(thresh_schedule[epoch])\n","        net.set_temperature(temperature_schedule[epoch])\n","\n","    loss_epoch = 0\n","    # trial=0\n","    for trial, (trainx, trainy) in enumerate(train_loader):  # ([1, 15000, 19]), ([1, 15000])\n","        if debugg == True:  # just test one trial\n","            if trial == 1:\n","                break\n","                pass\n","        optimizer.zero_grad()\n","\n","        if (enable_cuda):\n","            x = trainx.float().cuda()\n","            target = trainy.float().cuda()\n","        else:\n","            x = trainx.float()\n","            target = trainy.float()\n","        y_pred = net(x)\n","        # target = torch.from_numpy(target)\n","\n","        sup_loss, reg = loss_function(y_pred, target.float(), net,lamba, weight_decay)\n","        loss = sup_loss + reg  # regulization\n","        loss_epoch+=sup_loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(\"\" + str(epoch) + \" loss:\" + str(loss_epoch / (trial + 1)) + \".\")\n","    if epoch % 2 == 0:\n","        if net.enable_select==True:\n","            H, sel, probas = net.monitor()\n","            ax2.imshow(probas.cpu().detach().numpy(),origin='lower',cmap='RdBu_r',aspect='auto')\n","            im=ax2.images[-1]\n","            fig2.colorbar(im)\n","            fig2.savefig(pro_dir + 'prob_dist' + str(epoch) + '.png')\n","            im.colorbar.remove()\n","            ax2.clear()\n","\n","        net.eval()\n","        print(\"Validating...\")\n","        with torch.no_grad():\n","            vpredAll = []\n","            vtargetAll = []\n","            for trial, (vx, vtarget) in enumerate(val_loader):  # ([1, 15000, 19]), ([1, 15000])\n","                if (enable_cuda):\n","                    vx = vx.float().cuda()\n","                    vtarget = vtarget.float().cuda()\n","                else:\n","                    vx = vx.float()\n","                    vtarget = vtarget.float()\n","                y_pred = net(vx)\n","                \n","\n","                y_pred = y_pred.squeeze().cpu().detach().numpy()\n","                vtarget = vtarget.squeeze().cpu().numpy()\n","                vpredAll.append(y_pred)\n","                vtargetAll.append(vtarget)\n","\n","        vpredAll = np.concatenate(vpredAll, axis=0)\n","        vtargetAll = np.concatenate(vtargetAll, axis=0)\n","        #loss_val = criterion(torch.from_numpy(vpredAll.squeeze()), torch.from_numpy(vtargetAll.squeeze()))\n","\n","        pred_target=np.concatenate((vpredAll[:,None],vtargetAll[:,None]),axis=1)\n","        save_pred=saved_numpy + 'prediction_epoch' + str(epoch) + '.npy'\n","        np.save(save_pred, pred_target)\n","\n","        fig, ax = plt.subplots(figsize=(6, 3))\n","        plt.ion()\n","        ax.clear()\n","        ax.plot(vtargetAll, label=\"True\", linewidth=1)\n","        ax.plot(vpredAll, label='Predicted - Test', linewidth=1)\n","        ax.legend(loc='upper left')\n","        figname = result_dir + 'prediction' + str(epoch) + '.png'\n","        fig.savefig(figname)\n","        plt.close(fig)\n","    if epoch % 10 == 0:\n","        state = {\n","            'net': net.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","        }\n","        savepath = pths + 'checkpoint' + str(epoch) + '.pth'\n","        torch.save(state, savepath)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["------ epoch 0 -----\n","0 loss:0.3020581212372352.\n","Validating...\n","------ epoch 1 -----\n","1 loss:0.2140293407261881.\n","------ epoch 2 -----\n","2 loss:0.21142907033109257.\n","Validating...\n","------ epoch 3 -----\n","3 loss:0.2086142185343127.\n","------ epoch 4 -----\n","4 loss:0.20750610396648064.\n","Validating...\n","------ epoch 5 -----\n","5 loss:0.20507591663517505.\n","------ epoch 6 -----\n","6 loss:0.20641879504944524.\n","Validating...\n","------ epoch 7 -----\n","7 loss:0.20548654583274809.\n","------ epoch 8 -----\n","8 loss:0.20557235525204584.\n","Validating...\n","------ epoch 9 -----\n","9 loss:0.20513711172418717.\n","------ epoch 10 -----\n","10 loss:0.2049197609194069.\n","Validating...\n","------ epoch 11 -----\n","11 loss:0.20602465506929618.\n","------ epoch 12 -----\n","12 loss:0.20514855794926995.\n","Validating...\n","------ epoch 13 -----\n","13 loss:0.20560670082067323.\n","------ epoch 14 -----\n","14 loss:0.20567822063134777.\n","Validating...\n","------ epoch 15 -----\n","15 loss:0.203708058461929.\n","------ epoch 16 -----\n","16 loss:0.20683636013259235.\n","Validating...\n","------ epoch 17 -----\n","17 loss:0.20482727748333898.\n","------ epoch 18 -----\n","18 loss:0.20406243695407852.\n","Validating...\n","------ epoch 19 -----\n","19 loss:0.2075888311378976.\n","------ epoch 20 -----\n","20 loss:0.2050748386889951.\n","Validating...\n","------ epoch 21 -----\n","21 loss:0.20654707333534703.\n","------ epoch 22 -----\n","22 loss:0.20440876902614394.\n","Validating...\n","------ epoch 23 -----\n","23 loss:0.20561295467564183.\n","------ epoch 24 -----\n","24 loss:0.20430761999172023.\n","Validating...\n","------ epoch 25 -----\n","25 loss:0.2037817783590056.\n","------ epoch 26 -----\n","26 loss:0.20385181760558715.\n","Validating...\n","------ epoch 27 -----\n","27 loss:0.20292756876820683.\n","------ epoch 28 -----\n","28 loss:0.20420232233710778.\n","Validating...\n","------ epoch 29 -----\n","29 loss:0.20346299023964468.\n","------ epoch 30 -----\n","30 loss:0.20237722873496702.\n","Validating...\n","------ epoch 31 -----\n","31 loss:0.2041113375662229.\n","------ epoch 32 -----\n","32 loss:0.2029841197734205.\n","Validating...\n","------ epoch 33 -----\n","33 loss:0.2035318873822689.\n","------ epoch 34 -----\n","34 loss:0.20318900605934298.\n","Validating...\n","------ epoch 35 -----\n","35 loss:0.20252949574118495.\n","------ epoch 36 -----\n","36 loss:0.20319965354397765.\n","Validating...\n","------ epoch 37 -----\n","37 loss:0.20282068054199728.\n","------ epoch 38 -----\n","38 loss:0.20359714045865923.\n","Validating...\n","------ epoch 39 -----\n","39 loss:0.20341665164018288.\n","------ epoch 40 -----\n","40 loss:0.20351297503862625.\n","Validating...\n","------ epoch 41 -----\n","41 loss:0.20244891083457023.\n","------ epoch 42 -----\n","42 loss:0.20372710335585806.\n","Validating...\n","------ epoch 43 -----\n","43 loss:0.20316076106750047.\n","------ epoch 44 -----\n","44 loss:0.20284637035085604.\n","Validating...\n","------ epoch 45 -----\n","45 loss:0.2029340853039016.\n","------ epoch 46 -----\n","46 loss:0.20320794393873623.\n","Validating...\n","------ epoch 47 -----\n","47 loss:0.20299706717905325.\n","------ epoch 48 -----\n","48 loss:0.20281384245325357.\n","Validating...\n","------ epoch 49 -----\n","49 loss:0.20208009072921723.\n","------ epoch 50 -----\n","50 loss:0.20353311096501148.\n","Validating...\n","------ epoch 51 -----\n","51 loss:0.20508526633374202.\n","------ epoch 52 -----\n","52 loss:0.2035277861242111.\n","Validating...\n","------ epoch 53 -----\n","53 loss:0.20374747308400962.\n","------ epoch 54 -----\n","54 loss:0.20459253159471047.\n","Validating...\n","------ epoch 55 -----\n","55 loss:0.20392436685406753.\n","------ epoch 56 -----\n","56 loss:0.20453210248269588.\n","Validating...\n","------ epoch 57 -----\n","57 loss:0.2042206478679282.\n","------ epoch 58 -----\n","58 loss:0.20440821569317427.\n","Validating...\n","------ epoch 59 -----\n","59 loss:0.20406977211435637.\n","------ epoch 60 -----\n","60 loss:0.20428405663906.\n","Validating...\n","------ epoch 61 -----\n","61 loss:0.20375838735674182.\n","------ epoch 62 -----\n","62 loss:0.20395716660234153.\n","Validating...\n","------ epoch 63 -----\n","63 loss:0.20312059123037207.\n","------ epoch 64 -----\n","64 loss:0.20515046924607366.\n","Validating...\n","------ epoch 65 -----\n","65 loss:0.20388908620573518.\n","------ epoch 66 -----\n","66 loss:0.20392865811785063.\n","Validating...\n","------ epoch 67 -----\n","67 loss:0.20345073589720788.\n","------ epoch 68 -----\n","68 loss:0.2035022147445597.\n","Validating...\n","------ epoch 69 -----\n","69 loss:0.2033364061011463.\n","------ epoch 70 -----\n","70 loss:0.2034308936001144.\n","Validating...\n","------ epoch 71 -----\n","71 loss:0.20277241447096706.\n","------ epoch 72 -----\n","72 loss:0.20333537503949597.\n","Validating...\n","------ epoch 73 -----\n","73 loss:0.2034508486907197.\n","------ epoch 74 -----\n","74 loss:0.20423200812477332.\n","Validating...\n","------ epoch 75 -----\n","75 loss:0.2038354924123766.\n","------ epoch 76 -----\n","76 loss:0.2026004755598867.\n","Validating...\n","------ epoch 77 -----\n","77 loss:0.20282213650962228.\n","------ epoch 78 -----\n","78 loss:0.20384430105232784.\n","Validating...\n","------ epoch 79 -----\n","79 loss:0.2024639956653118.\n","------ epoch 80 -----\n","80 loss:0.20265630734527212.\n","Validating...\n","------ epoch 81 -----\n","81 loss:0.2029140522528408.\n","------ epoch 82 -----\n","82 loss:0.20416426760518652.\n","Validating...\n","------ epoch 83 -----\n","83 loss:0.20257403029717952.\n","------ epoch 84 -----\n","84 loss:0.20349759315578347.\n","Validating...\n","------ epoch 85 -----\n","85 loss:0.2018837351988778.\n","------ epoch 86 -----\n","86 loss:0.2013238964872992.\n","Validating...\n","------ epoch 87 -----\n","87 loss:0.20198861025592202.\n","------ epoch 88 -----\n","88 loss:0.20238111562963224.\n","Validating...\n","------ epoch 89 -----\n","89 loss:0.20017670610776314.\n","------ epoch 90 -----\n","90 loss:0.20153255900766096.\n","Validating...\n","------ epoch 91 -----\n","91 loss:0.2006719562296684.\n","------ epoch 92 -----\n","92 loss:0.2022465074227916.\n","Validating...\n","------ epoch 93 -----\n","93 loss:0.2013200118692003.\n","------ epoch 94 -----\n","94 loss:0.2035723608146366.\n","Validating...\n","------ epoch 95 -----\n","95 loss:0.20251512460601637.\n","------ epoch 96 -----\n","96 loss:0.2015096219495321.\n","Validating...\n","------ epoch 97 -----\n","97 loss:0.20174184944639859.\n","------ epoch 98 -----\n","98 loss:0.20212456755913222.\n","Validating...\n","------ epoch 99 -----\n","99 loss:0.2012711917806385.\n","------ epoch 100 -----\n","100 loss:0.19987733714664593.\n","Validating...\n","------ epoch 101 -----\n","101 loss:0.20411364855165157.\n","------ epoch 102 -----\n","102 loss:0.20162205111521941.\n","Validating...\n","------ epoch 103 -----\n","103 loss:0.20252825491703474.\n","------ epoch 104 -----\n","104 loss:0.2018615474494604.\n","Validating...\n","------ epoch 105 -----\n","105 loss:0.20225449667399764.\n","------ epoch 106 -----\n","106 loss:0.20211802002711174.\n","Validating...\n","------ epoch 107 -----\n","107 loss:0.20201647660543776.\n","------ epoch 108 -----\n","108 loss:0.20198491785643446.\n","Validating...\n","------ epoch 109 -----\n","109 loss:0.20197192630451968.\n","------ epoch 110 -----\n","110 loss:0.20198959309575903.\n","Validating...\n","------ epoch 111 -----\n","111 loss:0.202178847649668.\n","------ epoch 112 -----\n","112 loss:0.20195000596408152.\n","Validating...\n","------ epoch 113 -----\n","113 loss:0.2024409173327124.\n","------ epoch 114 -----\n","114 loss:0.20217555910985693.\n","Validating...\n","------ epoch 115 -----\n","115 loss:0.20174059806725916.\n","------ epoch 116 -----\n","116 loss:0.20152997120450705.\n","Validating...\n","------ epoch 117 -----\n","117 loss:0.20061301379504368.\n","------ epoch 118 -----\n","118 loss:0.20134949642750952.\n","Validating...\n","------ epoch 119 -----\n","119 loss:0.20106408359785366.\n","------ epoch 120 -----\n","120 loss:0.20139247551560402.\n","Validating...\n","------ epoch 121 -----\n","121 loss:0.20168204943084309.\n","------ epoch 122 -----\n","122 loss:0.2008791177127606.\n","Validating...\n","------ epoch 123 -----\n","123 loss:0.20069442530218354.\n","------ epoch 124 -----\n","124 loss:0.20020249243984875.\n","Validating...\n","------ epoch 125 -----\n","125 loss:0.20111257283606082.\n","------ epoch 126 -----\n","126 loss:0.20099676702903885.\n","Validating...\n","------ epoch 127 -----\n","127 loss:0.19945256144572526.\n","------ epoch 128 -----\n","128 loss:0.20018872590019152.\n","Validating...\n","------ epoch 129 -----\n","129 loss:0.2009874588340266.\n","------ epoch 130 -----\n","130 loss:0.1986393915473396.\n","Validating...\n","------ epoch 131 -----\n","131 loss:0.19966042618084157.\n","------ epoch 132 -----\n","132 loss:0.19919881455472901.\n","Validating...\n","------ epoch 133 -----\n","133 loss:0.19790130449283835.\n","------ epoch 134 -----\n","134 loss:0.1993714604112837.\n","Validating...\n","------ epoch 135 -----\n","135 loss:0.20050475666792983.\n","------ epoch 136 -----\n","136 loss:0.20083214762883309.\n","Validating...\n","------ epoch 137 -----\n","137 loss:0.19867303996131971.\n","------ epoch 138 -----\n","138 loss:0.1996498969502938.\n","Validating...\n","------ epoch 139 -----\n","139 loss:0.19968210896238303.\n","------ epoch 140 -----\n","140 loss:0.19965068889288312.\n","Validating...\n","------ epoch 141 -----\n","141 loss:0.19900193705390662.\n","------ epoch 142 -----\n","142 loss:0.20019626779816088.\n","Validating...\n","------ epoch 143 -----\n","143 loss:0.1994949099727166.\n","------ epoch 144 -----\n","144 loss:0.20047609428437346.\n","Validating...\n","------ epoch 145 -----\n","145 loss:0.1999143298365112.\n","------ epoch 146 -----\n","146 loss:0.2004871530792652.\n","Validating...\n","------ epoch 147 -----\n","147 loss:0.19915603480150557.\n","------ epoch 148 -----\n","148 loss:0.1987940446815939.\n","Validating...\n","------ epoch 149 -----\n","149 loss:0.2005253360312209.\n","------ epoch 150 -----\n","150 loss:0.19998363744563016.\n","Validating...\n","------ epoch 151 -----\n","151 loss:0.20103566389944819.\n","------ epoch 152 -----\n","152 loss:0.20290640894419107.\n","Validating...\n","------ epoch 153 -----\n","153 loss:0.20316296137678316.\n","------ epoch 154 -----\n","154 loss:0.20279226875585368.\n","Validating...\n","------ epoch 155 -----\n","155 loss:0.20216418942834577.\n","------ epoch 156 -----\n","156 loss:0.2000127128110482.\n","Validating...\n","------ epoch 157 -----\n","157 loss:0.20184191669791174.\n","------ epoch 158 -----\n","158 loss:0.20129673885038266.\n","Validating...\n","------ epoch 159 -----\n","159 loss:0.2007232152689726.\n","------ epoch 160 -----\n","160 loss:0.20156867442350102.\n","Validating...\n","------ epoch 161 -----\n","161 loss:0.20126631120458627.\n","------ epoch 162 -----\n","162 loss:0.20159271496356043.\n","Validating...\n","------ epoch 163 -----\n","163 loss:0.20112630597546569.\n","------ epoch 164 -----\n","164 loss:0.200653031309191.\n","Validating...\n","------ epoch 165 -----\n","165 loss:0.20197603998021182.\n","------ epoch 166 -----\n","166 loss:0.20151692122603074.\n","Validating...\n","------ epoch 167 -----\n","167 loss:0.20032792251843673.\n","------ epoch 168 -----\n","168 loss:0.19868785391251245.\n","Validating...\n","------ epoch 169 -----\n","169 loss:0.20159494497964525.\n","------ epoch 170 -----\n","170 loss:0.20263937739734975.\n","Validating...\n","------ epoch 171 -----\n","171 loss:0.20123708127146092.\n","------ epoch 172 -----\n","172 loss:0.2015727885449544.\n","Validating...\n","------ epoch 173 -----\n","173 loss:0.20090851152681896.\n","------ epoch 174 -----\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-e571da20e848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" loss:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_epoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}