{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main_base.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1oNSddmPYT8S4F9Ngr6nwU3pTPIoHVSQs","authorship_tag":"ABX9TyOB5JjWOleSqw8+DE8wQwur"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CYz-P2Bj7TIm"},"source":["# 1.   results:\n","\n","## windows=500\n","*   rawAndbands input: (windows/stride/accuracy)=500/50/99, 500/100/91, 500/200/77\n","*   raw input: (windows/stride/accuracy)= 500/50/99, 500/100/97, 500/200/83\n","\n","## windows=200\n","*  raw input: 200/200/44, 200/100/74, 200/50/96, \n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANOR3DiaMpoE","executionInfo":{"status":"ok","timestamp":1633073755778,"user_tz":-480,"elapsed":462,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"09dfdb8d-bcfa-44ef-e72a-efab4cb1b12b"},"source":["%cd /content/drive/MyDrive/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","metadata":{"id":"75yR8ulWMu62","executionInfo":{"status":"ok","timestamp":1633073813254,"user_tz":-480,"elapsed":56964,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["%%capture\n","! pip install hdf5storage\n","! pip install mne==0.23.0\n","! pip install torch==1.7.0\n","! pip install Braindecode==0.5.1\n","! pip install timm"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAiYT0gbMyaX","executionInfo":{"status":"ok","timestamp":1633073814673,"user_tz":-480,"elapsed":1434,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["import scipy.io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import mne\n","import torch\n","from torch.optim import lr_scheduler\n","from torch import nn\n","import timm\n","from common_dl import myDataset\n","from torch.utils.data import DataLoader\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from common_dl import set_random_seeds\n","from common_dsp import *\n","from gesture.models.d2l_resnet import d2lresnet\n","from myskorch import on_epoch_begin_callback, on_batch_end_callback\n","from ecog_finger.config import *\n","from ecog_finger.preprocess.chn_settings import  get_channel_setting\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkgUv_2zM0_9","executionInfo":{"status":"ok","timestamp":1633073814682,"user_tz":-480,"elapsed":12,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["try:\n","    mne.set_config('MNE_LOGGING_LEVEL','ERROR')\n","except TypeError as err:\n","    print(err)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NBuF2-rM2Os","executionInfo":{"status":"ok","timestamp":1633073814683,"user_tz":-480,"elapsed":12,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["sid=2\n","fs=1000\n","use_active_only=False\n","if use_active_only:\n","    active_chn=get_channel_setting(sid)\n","else:\n","    active_chn='all'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYAJF-LRVYlO","executionInfo":{"status":"ok","timestamp":1633073816968,"user_tz":-480,"elapsed":2297,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["input='rawAndbands'\n","input='raw'\n","if input=='raw':\n","    filename=data_dir+'fingerflex/data/'+str(sid)+'/'+str(sid)+'_fingerflex.mat'\n","    mat=scipy.io.loadmat(filename)\n","    data=mat['data'] # (46, 610040)\n","    data=data[:,:-1]\n","\n","    if 1==1:\n","        scaler = StandardScaler()\n","        scaler.fit(data)\n","        data=scaler.transform((data))\n","    data=np.transpose(data)\n","    chn_num=data.shape[0]\n","    flex=np.transpose(mat['flex']) #(5, 610040)\n","    cue=np.transpose(mat['cue']) # (1, 610040)\n","    data=np.concatenate((data,cue),axis=0) # (47, 610040) / (47, 610040)\n","\n","    chn_names=np.append([\"ecog\"]*chn_num,[\"stim\"])  #,\"thumb\",\"index\",\"middle\",\"ring\",\"little\"])\n","    chn_types=np.append([\"ecog\"]*chn_num,[\"stim\"])  #, \"emg\",\"emg\",\"emg\",\"emg\",\"emg\"])\n","    info = mne.create_info(ch_names=list(chn_names), ch_types=list(chn_types), sfreq=fs)\n","    raw = mne.io.RawArray(data, info)\n","\n","    events = mne.find_events(raw, stim_channel='stim')\n","    events=events-[0,0,1] #(150, 3)\n","    raw=raw.pick(picks=['ecog'])\n","\n","\n","    epochs = mne.Epochs(raw, events, tmin=0, tmax=2,baseline=None)\n","    # or epoch from 0s to 4s which only contain movement data.\n","    # epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)\n","\n","    epoch1=epochs['0'].get_data() # 20 trials. 8001 time points per trial for 8s.\n","    epoch2=epochs['1'].get_data()\n","    epoch3=epochs['2'].get_data()\n","    epoch4=epochs['3'].get_data()\n","    epoch5=epochs['4'].get_data()\n","    list_of_epochs = [epoch1, epoch2, epoch3, epoch4, epoch5]\n","    chn_num=epoch1.shape[1]\n","\n","elif input=='rawAndbands':\n","    list_of_epochs=[]\n","    save_to = data_dir + 'fingerflex/data/' + str(sid) + '/'\n","    for fingeri in range(5):\n","        tmp = mne.read_epochs(save_to + 'rawBandEpoch'+str(fingeri)+'.fif')\n","        list_of_epochs.append(tmp.get_data())\n","    chn_num=list_of_epochs[0].shape[1]\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5-_7mGqNGgm","executionInfo":{"status":"ok","timestamp":1633073816969,"user_tz":-480,"elapsed":8,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["wind=200\n","stride=200\n","s=0\n","X_train=[]\n","X_test=[]\n","labels_train=[]\n","labels_test=[]\n","total_len=list_of_epochs[0].shape[2]\n","labels=[]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvNXKIIpNJMp","executionInfo":{"status":"ok","timestamp":1633073816969,"user_tz":-480,"elapsed":7,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["test_number=10\n","for i in range(5):\n","    Xi_train = []\n","    Xi_test = []\n","    Xi=[]\n","    #ss=(total_len-wind)//stride\n","    for trial in list_of_epochs[i]: # (63, 2001)\n","        #trial=np.concatenate((trial,trial[-3:,:]),axis=0)\n","        s = 0\n","        while stride*s+wind<total_len:\n","            start=s * stride\n","            tmp=trial[:,start:(start+wind)]\n","            Xi.append(tmp)\n","            s=s+1\n","        # add the last window\n","        last_s=s-1\n","        if stride * last_s + wind<total_len-100:\n","            tmp=trial[:,-wind:]\n","            Xi.append(tmp)\n","    Xi_train=np.asarray(Xi[:-test_number]) # (260, 63, 500)\n","    Xi_test = np.asarray(Xi[-test_number:]) # (10, 63, 500)\n","\n","    X_train.append(Xi_train)\n","    X_test.append(Xi_test)\n","\n","    samples_number=len(Xi)\n","    label=[i]*samples_number\n","    label_train=label[:-test_number]\n","    label_test=label[-test_number:]\n","\n","    labels_train.append(label_train)\n","    labels_test.append(label_test)\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Vn1oB8EdwN4","executionInfo":{"status":"ok","timestamp":1633073816969,"user_tz":-480,"elapsed":7,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["X_train=np.concatenate(X_train,axis=0) # (1300, 63, 500)\n","X_test=np.concatenate(X_test,axis=0) # (50, 63, 500)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"WelESGUdNN2q","executionInfo":{"status":"ok","timestamp":1633073816970,"user_tz":-480,"elapsed":7,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["labels_train=np.asarray(labels_train)\n","labels_train=np.reshape(labels_train,(-1,1)) # (5, 270)\n","labels_test=np.asarray(labels_test)\n","labels_test=np.reshape(labels_test,(-1,1)) # (5, 270)\n","\n","# (871, 63, 500)/ (429, 63, 500)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, labels_train, test_size=0.33, random_state=42)\n","\n","train_set=myDataset(X_train,y_train)\n","val_set=myDataset(X_val,y_val)\n","\n","batch_size = 32\n","train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n","val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True, pin_memory=False)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZsxxcEaj6sy","executionInfo":{"status":"ok","timestamp":1633073816970,"user_tz":-480,"elapsed":7,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["train_size=len(train_loader.dataset)\n","val_size=len(val_loader.dataset)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwqm_nOlNQKd","executionInfo":{"status":"ok","timestamp":1633073816971,"user_tz":-480,"elapsed":8,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n","device = 'cuda' if cuda else 'cpu'\n","if cuda:\n","    torch.backends.cudnn.benchmark = True\n","seed = 20200220  # random seed to make results reproducible\n","set_random_seeds(seed=seed)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxs7p8ikNSOX","executionInfo":{"status":"ok","timestamp":1633073819790,"user_tz":-480,"elapsed":2826,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["#net=d2lresnet()\n","img_size=[chn_num,wind]\n","net = timm.create_model('visformer_tiny',num_classes=5,in_chans=1,img_size=img_size)\n","net = net.to(device)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VY-5J7PbIV_","executionInfo":{"status":"ok","timestamp":1633073819791,"user_tz":-480,"elapsed":15,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":["lr = 0.05\n","weight_decay = 1e-10\n","epoch_num = 500\n","\n","criterion = nn.CrossEntropyLoss()\n","#criterion = nn.NLLLoss()\n","#optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n","optimizer = torch.optim.Adadelta(net.parameters(), lr=lr)\n","#optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","# Decay LR by a factor of 0.1 every 7 epochs\n","lr_schedulerr = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","epoch_num = 500"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFwHkb2dNXER","executionInfo":{"status":"ok","timestamp":1633074584522,"user_tz":-480,"elapsed":764746,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"2ebcb30a-df1d-4e8c-e890-394cfbd881ac"},"source":["for epoch in range(epoch_num):\n","    print(\"------ epoch \" + str(epoch) + \" -----\")\n","    net.train()\n","\n","    loss_epoch = 0\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    for batch, (trainx, trainy) in enumerate(train_loader):\n","        trainx=torch.unsqueeze(trainx,dim=1)\n","        optimizer.zero_grad()\n","        if (cuda):\n","            trainx = trainx.float().cuda()\n","        else:\n","            trainx = trainx.float()\n","        y_pred = net(trainx)\n","        #print(\"y_pred shape: \" + str(y_pred.shape))\n","        preds = y_pred.argmax(dim=1, keepdim=True)\n","        #_, preds = torch.max(y_pred, 1)\n","\n","        if cuda:\n","            loss = criterion(y_pred, trainy.squeeze().cuda())\n","        else:\n","            loss = criterion(y_pred, trainy.squeeze())\n","\n","        loss.backward()  # calculate the gradient and store in .grad attribute.\n","        optimizer.step()\n","        running_loss += loss.item() * trainx.shape[0]\n","        running_corrects += torch.sum(preds.cpu().squeeze() == trainy.squeeze())\n","    #print(\"train_size: \" + str(train_size))\n","    lr_schedulerr.step() # test it\n","    epoch_loss = running_loss / train_size\n","    epoch_acc = running_corrects.double() / train_size\n","    print(\"Training loss: {:.2f}; Accuracy: {:.2f}.\".format(epoch_loss,epoch_acc.item()))\n","    #print(\"Training \" + str(epoch) + \": loss: \" + str(epoch_loss) + \",\" + \"Accuracy: \" + str(epoch_acc.item()) + \".\")\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    if epoch % 1 == 0:\n","        net.eval()\n","        # print(\"Validating...\")\n","        with torch.no_grad():\n","            for _, (val_x, val_y) in enumerate(val_loader):\n","                val_x = torch.unsqueeze(val_x, dim=1)\n","                if (cuda):\n","                    val_x = val_x.float().cuda()\n","                    # val_y = val_y.float().cuda()\n","                else:\n","                    val_x = val_x.float()\n","                    # val_y = val_y.float()\n","                outputs = net(val_x)\n","                #_, preds = torch.max(outputs, 1)\n","                preds = outputs.argmax(dim=1, keepdim=True)\n","\n","                running_corrects += torch.sum(preds.cpu().squeeze() == val_y.squeeze())\n","\n","        epoch_acc = running_corrects.double() / val_size\n","        print(\"Evaluation accuracy: {:.2f}.\".format(epoch_acc.item()))\n"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["------ epoch 0 -----\n","Training loss: 1.53; Accuracy: 0.32.\n","Evaluation accuracy: 0.33.\n","------ epoch 1 -----\n","Training loss: 1.23; Accuracy: 0.49.\n","Evaluation accuracy: 0.31.\n","------ epoch 2 -----\n","Training loss: 0.98; Accuracy: 0.65.\n","Evaluation accuracy: 0.32.\n","------ epoch 3 -----\n","Training loss: 0.76; Accuracy: 0.74.\n","Evaluation accuracy: 0.37.\n","------ epoch 4 -----\n","Training loss: 0.58; Accuracy: 0.81.\n","Evaluation accuracy: 0.36.\n","------ epoch 5 -----\n","Training loss: 0.44; Accuracy: 0.86.\n","Evaluation accuracy: 0.42.\n","------ epoch 6 -----\n","Training loss: 0.28; Accuracy: 0.93.\n","Evaluation accuracy: 0.38.\n","------ epoch 7 -----\n","Training loss: 0.22; Accuracy: 0.95.\n","Evaluation accuracy: 0.39.\n","------ epoch 8 -----\n","Training loss: 0.15; Accuracy: 0.96.\n","Evaluation accuracy: 0.36.\n","------ epoch 9 -----\n","Training loss: 0.10; Accuracy: 0.98.\n","Evaluation accuracy: 0.39.\n","------ epoch 10 -----\n","Training loss: 0.09; Accuracy: 0.98.\n","Evaluation accuracy: 0.39.\n","------ epoch 11 -----\n","Training loss: 0.07; Accuracy: 0.99.\n","Evaluation accuracy: 0.38.\n","------ epoch 12 -----\n","Training loss: 0.06; Accuracy: 0.99.\n","Evaluation accuracy: 0.39.\n","------ epoch 13 -----\n","Training loss: 0.06; Accuracy: 0.99.\n","Evaluation accuracy: 0.35.\n","------ epoch 14 -----\n","Training loss: 0.05; Accuracy: 0.99.\n","Evaluation accuracy: 0.40.\n","------ epoch 15 -----\n","Training loss: 0.05; Accuracy: 0.99.\n","Evaluation accuracy: 0.42.\n","------ epoch 16 -----\n","Training loss: 0.02; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 17 -----\n","Training loss: 0.06; Accuracy: 0.98.\n","Evaluation accuracy: 0.41.\n","------ epoch 18 -----\n","Training loss: 0.04; Accuracy: 0.99.\n","Evaluation accuracy: 0.39.\n","------ epoch 19 -----\n","Training loss: 0.05; Accuracy: 0.98.\n","Evaluation accuracy: 0.42.\n","------ epoch 20 -----\n","Training loss: 0.08; Accuracy: 0.98.\n","Evaluation accuracy: 0.43.\n","------ epoch 21 -----\n","Training loss: 0.03; Accuracy: 0.99.\n","Evaluation accuracy: 0.45.\n","------ epoch 22 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 23 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 24 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 25 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 26 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 27 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 28 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 29 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 30 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 31 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 32 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 33 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 34 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 35 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 36 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 37 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 38 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 39 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 40 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 41 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 42 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 43 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 44 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 45 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 46 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 47 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 48 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 49 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 50 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 51 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 52 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 53 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 54 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 55 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 56 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 57 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 58 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 59 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 60 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 61 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 62 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 63 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 64 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 65 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 66 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 67 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 68 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 69 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 70 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 71 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 72 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 73 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 74 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 75 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 76 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 77 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 78 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 79 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 80 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 81 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 82 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 83 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 84 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 85 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 86 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 87 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 88 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 89 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 90 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 91 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 92 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 93 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 94 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 95 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 96 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 97 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 98 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 99 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 100 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 101 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 102 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 103 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 104 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 105 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 106 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 107 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 108 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 109 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 110 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 111 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 112 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 113 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 114 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 115 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 116 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 117 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 118 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 119 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 120 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 121 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 122 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 123 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 124 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 125 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 126 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 127 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 128 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 129 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 130 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 131 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 132 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 133 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 134 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 135 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 136 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 137 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 138 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 139 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 140 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 141 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 142 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 143 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 144 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 145 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 146 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 147 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 148 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 149 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 150 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 151 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 152 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 153 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 154 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 155 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 156 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 157 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 158 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 159 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 160 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 161 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 162 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 163 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 164 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 165 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 166 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 167 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 168 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 169 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 170 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 171 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 172 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 173 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 174 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 175 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 176 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 177 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 178 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 179 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 180 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 181 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 182 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 183 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 184 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 185 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 186 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 187 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 188 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 189 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 190 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 191 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 192 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 193 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 194 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 195 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 196 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 197 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 198 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 199 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 200 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 201 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 202 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 203 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 204 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 205 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 206 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 207 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 208 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 209 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 210 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 211 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 212 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 213 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 214 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 215 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 216 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 217 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 218 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 219 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 220 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 221 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 222 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 223 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 224 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 225 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 226 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 227 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 228 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 229 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 230 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 231 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 232 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 233 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 234 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 235 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 236 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 237 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 238 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 239 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 240 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 241 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 242 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 243 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 244 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 245 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 246 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 247 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 248 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 249 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 250 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 251 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 252 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 253 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 254 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 255 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 256 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 257 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 258 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 259 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 260 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 261 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 262 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 263 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 264 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 265 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 266 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 267 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 268 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 269 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 270 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 271 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 272 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 273 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 274 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 275 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 276 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 277 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 278 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 279 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 280 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 281 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 282 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 283 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 284 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 285 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 286 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 287 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 288 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 289 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 290 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 291 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 292 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 293 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 294 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 295 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 296 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 297 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 298 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 299 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 300 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 301 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 302 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 303 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 304 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 305 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 306 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 307 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 308 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 309 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 310 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 311 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 312 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 313 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 314 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 315 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 316 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 317 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 318 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 319 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 320 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 321 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 322 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 323 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 324 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 325 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 326 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 327 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 328 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 329 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 330 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 331 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 332 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 333 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 334 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 335 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 336 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 337 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 338 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 339 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 340 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 341 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 342 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 343 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 344 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 345 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 346 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 347 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 348 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 349 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 350 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 351 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 352 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 353 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 354 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 355 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 356 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 357 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 358 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 359 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 360 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 361 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 362 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 363 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 364 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 365 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 366 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 367 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 368 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 369 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 370 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 371 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 372 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 373 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 374 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 375 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 376 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 377 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 378 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 379 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 380 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 381 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 382 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 383 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 384 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 385 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 386 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 387 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 388 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 389 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 390 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 391 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 392 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 393 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 394 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 395 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 396 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 397 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 398 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 399 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 400 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 401 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 402 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 403 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 404 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 405 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 406 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 407 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 408 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 409 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 410 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 411 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 412 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 413 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 414 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 415 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 416 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 417 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 418 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 419 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.42.\n","------ epoch 420 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 421 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 422 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 423 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 424 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 425 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 426 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 427 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 428 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 429 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 430 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 431 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 432 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 433 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 434 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 435 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 436 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 437 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 438 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 439 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 440 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 441 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 442 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 443 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 444 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 445 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 446 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 447 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 448 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 449 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 450 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 451 -----\n","Training loss: 0.02; Accuracy: 0.99.\n","Evaluation accuracy: 0.45.\n","------ epoch 452 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 453 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 454 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 455 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 456 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 457 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 458 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 459 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 460 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 461 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 462 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 463 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 464 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 465 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 466 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 467 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 468 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 469 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 470 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 471 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.46.\n","------ epoch 472 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 473 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 474 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 475 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 476 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 477 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 478 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 479 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 480 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 481 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 482 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 483 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 484 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 485 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 486 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 487 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 488 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 489 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 490 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.45.\n","------ epoch 491 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 492 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 493 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 494 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 495 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 496 -----\n","Training loss: 0.00; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 497 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n","------ epoch 498 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.43.\n","------ epoch 499 -----\n","Training loss: 0.01; Accuracy: 1.00.\n","Evaluation accuracy: 0.44.\n"]}]},{"cell_type":"code","metadata":{"id":"Nv-zbCVueV75","executionInfo":{"status":"ok","timestamp":1633074584522,"user_tz":-480,"elapsed":15,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}}},"source":[""],"execution_count":15,"outputs":[]}]}