{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main_selection.ipynb","provenance":[{"file_id":"1EYz0RDU00kpyR70LFTuucwD2tc_ry_fQ","timestamp":1618074355729}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1KJ9JMFr-pFEXS2ClisAWvjZT0ZUzq3M4","authorship_tag":"ABX9TyNfVDd1fMX65w0fLgoTcMKU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"uafsleT3yacC"},"source":["# grid search result not good at all: at chance level.\n","# try use different thresh tau parameter=selection_number instead of 3.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CL_MTaBMQ9-p","executionInfo":{"status":"ok","timestamp":1634123614800,"user_tz":-480,"elapsed":466,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"fb4bf7aa-18c9-444e-efea-dd5f4c8a661c"},"source":["%cd /content/drive/MyDrive/\n","# raw_data is imported from global config"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","metadata":{"id":"xwROBJfQRAYe"},"source":["%%capture\n","! pip install hdf5storage\n","! pip install mne==0.23.0\n","! pip install torch\n","! pip install Braindecode==0.5.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i57D8rprx4fD","executionInfo":{"status":"ok","timestamp":1634123629934,"user_tz":-480,"elapsed":1536,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"368cab65-115a-4b60-ef91-8d74de17b04a"},"source":["import sys\n","import socket\n","if socket.gethostname() == 'workstation':\n","    sys.path.extend(['C:/Users/wuxiaolong/Desktop/BCI/googledrive'])\n","elif socket.gethostname() == 'longsMac':\n","    sys.path.extend(['/Users/long/Documents/BCI/python_scripts/googleDrive'])\n","from gesture.config import *"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting to create new mne-python configuration file:\n","/root/.mne/mne-python.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"9NQVV2AYNaLO"},"source":["***Copy and Paste your code below.***"]},{"cell_type":"code","metadata":{"id":"W2RjuTz5T_ez"},"source":["import os, re\n","import matplotlib.pyplot as plt\n","import hdf5storage\n","import numpy as np\n","import torch\n","import random\n","from common_dl import set_random_seeds\n","from common_dl import myDataset\n","from comm_utils import slide_epochs\n","from torch.utils.data import DataLoader\n","from sklearn.preprocessing import StandardScaler\n","from torch.optim import lr_scheduler\n","from gesture.models.deepmodel import deepnet,deepnet_resnet\n","from example.gumbelSelection.ChannelSelection.models import MSFBCNN\n","from gesture.models.selectionModels import selectionNet\n","\n","from gesture.myskorch import on_epoch_begin_callback, on_batch_end_callback\n","from gesture.preprocess.chn_settings import get_channel_setting\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","seed = 20200220  # random seed to make results reproducible\n","set_random_seeds(seed=seed)\n","\n","cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n","device = 'cuda' if cuda else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9or620gc2Bk"},"source":["import inspect as i\n","import sys\n","#sys.stdout.write(i.getsource(deepnet))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Svy7ABlg3wuE"},"source":["sid=10 #4\n","class_number=5\n","Session_num,UseChn,EmgChn,TrigChn, activeChan = get_channel_setting(sid)\n","#fs=[Frequencies[i,1] for i in range(Frequencies.shape[0]) if Frequencies[i,0] == sid][0]\n","fs=1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oz5sEhP6Mu4b"},"source":["project_dir=data_dir+'preprocessing'+'/P'+str(sid)+'/'\n","result_dir=project_dir + 'result' + '/'\n","model_path=project_dir + 'pth' +'/'\n","if not os.path.exists(result_dir):\n","    os.makedirs(result_dir)\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_np8cCh3reZN","executionInfo":{"status":"ok","timestamp":1634123639843,"user_tz":-480,"elapsed":7,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"298f996f-f744-48c7-bc56-78e21e6d2968"},"source":["[Frequencies[i,1] for i in range(Frequencies.shape[0]) if Frequencies[i,0] == sid][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"1LBbiAuvUVb_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634123752221,"user_tz":-480,"elapsed":16504,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"c1e61b8d-c7d9-449a-8ee3-3a39679098e1"},"source":["loadPath = data_dir+'preprocessing'+'/P'+str(sid)+'/preprocessing2.mat'\n","mat=hdf5storage.loadmat(loadPath)\n","data = mat['Datacell']\n","channelNum=int(mat['channelNum'][0,0])\n","data=np.concatenate((data[0,0],data[0,1]),0)\n","del mat\n","# standardization\n","# no effect. why?\n","if 1==1:\n","    chn_data=data[:,-3:]\n","    data=data[:,:-3]\n","    scaler = StandardScaler()\n","    scaler.fit(data)\n","    data=scaler.transform((data))\n","    data=np.concatenate((data,chn_data),axis=1)\n","\n","# stim0 is trigger channel, stim1 is trigger position calculated from EMG signal.\n","chn_names=np.append([\"seeg\"]*len(UseChn),[\"stim0\", \"emg\",\"stim1\"])\n","chn_types=np.append([\"seeg\"]*len(UseChn),[\"stim\", \"emg\",\"stim\"])\n","info = mne.create_info(ch_names=list(chn_names), ch_types=list(chn_types), sfreq=fs)\n","raw = mne.io.RawArray(data.transpose(), info)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating RawArray with float64 data, n_channels=211, n_times=1052092\n","    Range : 0 ... 1052091 =      0.000 ...  1052.091 secs\n","Ready.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-f8fbb8d4d7dc>:20: RuntimeWarning: Channel names are not unique, found duplicates for: {'seeg'}. Applying running numbers for duplicates.\n","  info = mne.create_info(ch_names=list(chn_names), ch_types=list(chn_types), sfreq=fs)\n"]}]},{"cell_type":"code","metadata":{"id":"NxbH3k2Ej3SF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634123754640,"user_tz":-480,"elapsed":721,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"87936866-5a00-466f-f7a0-7b0fd05a5b8d"},"source":["# gesture/events type: 1,2,3,4,5\n","events0 = mne.find_events(raw, stim_channel='stim0')\n","events1 = mne.find_events(raw, stim_channel='stim1')\n","# events number should start from 0: 0,1,2,3,4, instead of 1,2,3,4,5\n","events0=events0-[0,0,1]\n","events1=events1-[0,0,1]\n","\n","#print(events[:5])  # show the first 5\n","# Epoch from 4s before(idle) until 4s after(movement) stim1.\n","raw=raw.pick([\"seeg\"])\n","epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)\n","# or epoch from 0s to 4s which only contain movement data.\n","# epochs = mne.Epochs(raw, events1, tmin=0, tmax=4,baseline=None)\n","\n","epoch1=epochs['0'].get_data() # 20 trials. 8001 time points per trial for 8s.\n","epoch2=epochs['1'].get_data()\n","epoch3=epochs['2'].get_data()\n","epoch4=epochs['3'].get_data()\n","epoch5=epochs['4'].get_data()\n","list_of_epochs=[epoch1,epoch2,epoch3,epoch4,epoch5]\n","total_len=list_of_epochs[0].shape[2]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100 events found\n","Event IDs: [1 2 3 4 5]\n","100 events found\n","Event IDs: [1 2 3 4 5]\n","Not setting metadata\n","Not setting metadata\n","100 matching events found\n","No baseline correction applied\n","0 projection items activated\n","Loading data for 20 events and 4001 original time points ...\n","0 bad epochs dropped\n","Loading data for 20 events and 4001 original time points ...\n","0 bad epochs dropped\n","Loading data for 20 events and 4001 original time points ...\n","0 bad epochs dropped\n","Loading data for 20 events and 4001 original time points ...\n","0 bad epochs dropped\n","Loading data for 20 events and 4001 original time points ...\n","0 bad epochs dropped\n"]}]},{"cell_type":"code","metadata":{"id":"nIk1R-88npSy"},"source":["# validate=test=2 trials\n","trial_number=[list(range(epochi.shape[0])) for epochi in list_of_epochs] #[ [0,1,2,...19],[0,1,2...19],... ]\n","test_trials=[random.sample(epochi, 2) for epochi in trial_number]\n","# len(test_trials[0]) # test trials number\n","trial_number_left=[np.setdiff1d(trial_number[i],test_trials[i]) for i in range(class_number)]\n","\n","val_trials=[random.sample(list(epochi), 2) for epochi in trial_number_left]\n","train_trials=[np.setdiff1d(trial_number_left[i],val_trials[i]).tolist() for i in range(class_number)]\n","\n","# no missing trials\n","assert [sorted(test_trials[i]+val_trials[i]+train_trials[i]) for i in range(class_number)] == trial_number\n","\n","test_epochs=[epochi[test_trials[clas],:,:] for clas,epochi in enumerate(list_of_epochs)] # [ epoch0,epoch1,epch2,epoch3,epoch4 ]\n","val_epochs=[epochi[val_trials[clas],:,:] for clas,epochi in enumerate(list_of_epochs)]\n","train_epochs=[epochi[train_trials[clas],:,:] for clas,epochi in enumerate(list_of_epochs)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edBaRd88j-DC"},"source":["wind=500\n","stride=50\n","X_train=[]\n","y_train=[]\n","X_val=[]\n","y_val=[]\n","X_test=[]\n","y_test=[]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRvhrhARn_4C"},"source":["for clas, epochi in enumerate(test_epochs):\n","    Xi,y=slide_epochs(epochi,clas,wind, stride)\n","    assert Xi.shape[0]==len(y)\n","    X_test.append(Xi)\n","    y_test.append(y)\n","X_test=np.concatenate(X_test,axis=0) # (1300, 63, 500)\n","y_test=np.asarray(y_test)\n","y_test=np.reshape(y_test,(-1,1)) # (5, 270)\n","\n","for clas, epochi in enumerate(val_epochs):\n","    Xi,y=slide_epochs(epochi,clas,wind, stride)\n","    assert Xi.shape[0]==len(y)\n","    X_val.append(Xi)\n","    y_val.append(y)\n","X_val=np.concatenate(X_val,axis=0) # (1300, 63, 500)\n","y_val=np.asarray(y_val)\n","y_val=np.reshape(y_val,(-1,1)) # (5, 270)\n","\n","for clas, epochi in enumerate(train_epochs):\n","    Xi,y=slide_epochs(epochi,clas,wind, stride)\n","    assert Xi.shape[0]==len(y)\n","    X_train.append(Xi)\n","    y_train.append(y)\n","X_train=np.concatenate(X_train,axis=0) # (1300, 63, 500)\n","y_train=np.asarray(y_train)\n","y_train=np.reshape(y_train,(-1,1)) # (5, 270)\n","chn_num=X_train.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJIQ3MlgIctg"},"source":["train_set=myDataset(X_train,y_train)\n","val_set=myDataset(X_val,y_val)\n","test_set=myDataset(X_test,y_test)\n","\n","batch_size = 32\n","train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n","val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n","test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True, pin_memory=False)\n","\n","train_size=len(train_loader.dataset)\n","val_size=len(val_loader.dataset)\n","test_size=len(test_loader.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"icHBaZeXkn85"},"source":["# These values we found good for shallow network:\n","lr = 0.0001\n","weight_decay = 1e-10\n","batch_size = 32\n","n_epochs = 200"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dwSdXmELvk9"},"source":["#one_window.shape : (208, 500)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nSrQqFFGkeK-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634123771032,"user_tz":-480,"elapsed":9536,"user":{"displayName":"Long WU","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYKa6__vAaw1RpvqUkOWX7cZ5xvDbUQ1ovLHLL=s64","userId":"09414210733761439327"}},"outputId":"4e9f67eb-0496-47d1-9cb2-67a032df39af"},"source":["# Extract number of chans and time steps from dataset\n","one_window=next(iter(train_set))[0]\n","n_chans = one_window.shape[0]\n","\n","img_size=[n_chans,wind]\n","#net = timm.create_model('visformer_tiny',num_classes=n_classes,in_chans=1,img_size=img_size)\n","#net = deepnet(n_chans,class_number,input_window_samples=wind,final_conv_length='auto',) # 81%\n","selection_number=10\n","net = selectionNet(n_chans,class_number,wind,selection_number) # 81%\n","#net=MSFBCNN([n_chans,wind],class_number)\n","\n","if cuda:\n","    net.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"code","metadata":{"id":"CEaQcyBVvq-0"},"source":["if isinstance(net, selectionNet):\n","    optimizer = torch.optim.Adadelta(\n","    [\n","        {\"params\": net.selection_layer.parameters(), \"lr\": 1e-3},\n","        {\"params\": net.network.parameters(),\"lr\":0.05},\n","    ],\n","    lr=0.0,\n","    )\n","else:\n","    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfRAQCa1JPp-"},"source":["#lr = 0.002\n","#weight_decay = 1e-10\n","weight_decay = 5e-4\n","lamba=0.1\n","epoch_num = 100\n","criterion = torch.nn.CrossEntropyLoss()\n","#criterion = nn.NLLLoss()\n","#optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n","#optimizer = torch.optim.Adadelta(net.parameters(), lr=lr)\n","#optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","# Decay LR by a factor of 0.1 every 7 epochs\n","lr_schedulerr = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yc5kYun0vu_9"},"source":["def exponential_decay_schedule(start_value,end_value,epochs,end_epoch):\n","    t = torch.FloatTensor(torch.arange(0.0,epochs))\n","    p = torch.clamp(t/end_epoch,0,1)\n","    out = start_value*torch.pow(end_value/start_value,p)\n","\n","    return out\n","start_temp=10\n","end_temp=0.1\n","temperature_schedule = exponential_decay_schedule(start_temp,end_temp,epoch_num,int(epoch_num*3/4))\n","thresh_schedule = exponential_decay_schedule(selection_number,1.1,epoch_num,epoch_num)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbIa4ixsjUhm"},"source":["import inspect as i\n","import sys\n","#sys.stdout.write(i.getsource(selectionNet))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWDgrWkYv5Wy"},"source":["if isinstance(net, selectionNet):\n","    fig, ax=plt.subplots()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyUFQVl7lW8s"},"source":["if isinstance(net, selectionNet):\n","    net.set_freeze(False)\n","\n","H=[]\n","S=[]\n","Z=[]\n","\n","epoch_score=[]\n","for epoch in range(epoch_num):\n","    epoch_score.append([])\n","    H.append([])\n","    S.append([])\n","    Z.append([])\n","    print(\"------ epoch \" + str(epoch) + \" -----\")\n","    \n","    if isinstance(net, selectionNet):\n","        net.set_thresh(thresh_schedule[epoch])\n","        net.set_temperature(temperature_schedule[epoch])\n","    net.train()\n","\n","    loss_epoch = 0\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    for batch, (trainx, trainy) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        if (cuda):\n","            trainx = trainx.float().cuda()\n","        else:\n","            trainx = trainx.float()\n","        y_pred = net(trainx)\n","        #print(\"y_pred shape: \" + str(y_pred.shape))\n","        preds = y_pred.argmax(dim=1, keepdim=True)\n","        #_, preds = torch.max(y_pred, 1)\n","\n","        if cuda:\n","            loss = criterion(y_pred, trainy.squeeze().cuda().long())\n","        else:\n","            loss = criterion(y_pred, trainy.squeeze())\n","        if isinstance(net, selectionNet):\n","            reg = net.regularizer(lamba,weight_decay)\n","            loss=loss+reg\n","        loss.backward()  # calculate the gradient and store in .grad attribute.\n","        optimizer.step()\n","        running_loss += loss.item() * trainx.shape[0]\n","        running_corrects += torch.sum(preds.cpu().squeeze() == trainy.squeeze())\n","    #print(\"train_size: \" + str(train_size))\n","    lr_schedulerr.step() # test it\n","    epoch_loss = running_loss / train_size\n","    train_acc = running_corrects.double() / train_size\n","    epoch_score[epoch].append(train_acc)\n","    print(\"Training loss: {:.2f}; Accuracy: {:.2f}.\".format(epoch_loss,train_acc.item()))\n","    #print(\"Training \" + str(epoch) + \": loss: \" + str(epoch_loss) + \",\" + \"Accuracy: \" + str(epoch_acc.item()) + \".\")\n","\n","    state = {\n","            'net': net.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","             'epoch': epoch,\n","             'loss': epoch_loss\n","        }\n","    savepath = model_path + 'checkpoint' + str(epoch) + '.pth'\n","    #torch.save(state, savepath)\n","\n","    if isinstance(net, selectionNet):\n","        hi, sel, probas = net.monitor()\n","        H[epoch].append(hi)\n","        S[epoch].append(sel)\n","        Z[epoch].append(probas)\n","        ax.plot(probas.detach().cpu().numpy())\n","        #fig.savefig(result_dir + 'prob_dist' + str(epoch) + '.png')\n","        ax.clear()\n","\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    if epoch % 1 == 0:\n","        with torch.no_grad():\n","            net.eval()\n","            # print(\"Validating...\")\n","            with torch.no_grad():\n","                for _, (val_x, val_y) in enumerate(val_loader):\n","                    if (cuda):\n","                        val_x = val_x.float().cuda()\n","                        # val_y = val_y.float().cuda()\n","                    else:\n","                        val_x = val_x.float()\n","                        # val_y = val_y.float()\n","                    outputs = net(val_x)\n","                    #_, preds = torch.max(outputs, 1)\n","                    preds = outputs.argmax(dim=1, keepdim=True)\n","\n","                    running_corrects += torch.sum(preds.cpu().squeeze() == val_y.squeeze())\n","\n","            val_acc = running_corrects.double() / val_size\n","            print(\"Evaluation accuracy: {:.2f}.\".format(val_acc.item()))\n","    epoch_score[epoch].append(val_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3i7COaAZMPy-"},"source":["epoch_score=np.asarray(epoch_score)\n","filename = result_dir + 'epoch_scores' + str(selection_lr)+'_'+str(network_lr)\n","np.save(filename,epoch_score)\n","HH=np.asarray(H)\n","filename = result_dir + 'HH' + str(selection_lr)+'_'+str(network_lr)\n","np.save(filename,HH)\n","SS=np.asarray(S)\n","filename = result_dir + 'SS' + str(selection_lr)+'_'+str(network_lr)\n","np.save(filename,SS)\n","ZZ=np.asarray(Z)\n","filename = result_dir + 'ZZ' + str(selection_lr)+'_'+str(network_lr)\n","np.save(filename,ZZ)\n","\n"],"execution_count":null,"outputs":[]}]}