{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSceptionBandInput.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL_MTaBMQ9-p",
        "outputId": "6697ceec-cdb6-48f9-bae3-769e605921dd"
      },
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "# raw_data is imported from global config\n",
        "root_dir='/content/drive/MyDrive/'  # ChangeThis\n",
        "result_dir=root_dir+'grasp/TSception/result_test_dropout/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiU4GcMWzaFT"
      },
      "source": [
        "import sys, importlib\n",
        "#importlib.reload(sys.modules['grasp.config'])\n",
        "from grasp.config import data_dir\n",
        "# orveride the data_dir in config file\n",
        "#data_dir='/content/drive/MyDrive/data/' # googleDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N4zjc3vuPTZJ",
        "outputId": "a8fc805d-45a8-4e65-dd1f-d4838a73bbde"
      },
      "source": [
        "data_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/data/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwROBJfQRAYe",
        "outputId": "b04470ac-a93e-47f3-a234-51300c5f1aa8"
      },
      "source": [
        "! pip install mne==0.19.2;\n",
        "! pip install torch;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne==0.19.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/7c/ad1b52a3fdd4be8f55e183f1eff7d76f48cd1bee83c5630f9c26770e032e/mne-0.19.2-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mne==0.19.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from mne==0.19.2) (1.19.5)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQOkCPEnRJ7G"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from grasp.TSception.utils import regulization\n",
        "from grasp.utils import SEEGDataset,SEEGDataset1\n",
        "from grasp.TSception.Models import TSception\n",
        "\n",
        "# load the data: regression to target force derivative\n",
        "from grasp.utils import rawData2\n",
        "from grasp.config import activeChannels, root_dir\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O01RtPYIVdvd"
      },
      "source": [
        "# reload function\n",
        "import sys, importlib\n",
        "importlib.reload(sys.modules['grasp.TSception.Models'])\n",
        "importlib.reload(sys.modules['grasp.utils'])\n",
        "\n",
        "from grasp.utils import SEEGDataset,SEEGDataset1\n",
        "from grasp.TSception.Models import TSception,TSception2\n",
        "from grasp.utils import rawData2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppXUCroiY2iC"
      },
      "source": [
        "# import from another folder\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/MyDrive/examples')\n",
        "from IMV_LSTM.networks import IMVTensorLSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dt_Bz4ztzear",
        "outputId": "f05d8e7b-6a11-4b03-9b95-fbd441990afc"
      },
      "source": [
        "data_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/data/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IjnSRE7WSZt"
      },
      "source": [
        "import inspect as i\n",
        "import sys\n",
        "#sys.stdout.write(i.getsource(rawData2));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BjdQBwjTddA",
        "outputId": "e943083f-be19-45d0-ff20-dada829823fb"
      },
      "source": [
        "enable_cuda = torch.cuda.is_available()\n",
        "print('GPU computing: ', enable_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU computing:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvPvrrXZaOv"
      },
      "source": [
        "%%capture\n",
        "# suppress the output\n",
        "sampling_rate=1000\n",
        "#traindata, valdata, testdata = rawData2('raw',activeChannels,move2=False)  # (chns, 15000/15001, 118) (channels, time, trials)\n",
        "traindata, valdata, testdata = rawData2('band','all',move2=True)\n",
        "traindata = traindata.transpose(2, 0, 1)  # (118, 20, 15000) (trials,channels,  time)\n",
        "valdata = valdata.transpose(2, 0, 1) # (8, 20, 15000)\n",
        "testdata = testdata.transpose(2, 0, 1)  # (8, 20, 15000)\n",
        "trainx_ds, trainy_ds = traindata[:, :-2, :], traindata[:, -2, :] #-2 is real force, -1 is target\n",
        "valx_ds, valy_ds = valdata[:, :-2, :], valdata[:, -2, :]\n",
        "testx_ds, testy_ds = testdata[:, :-2, :], testdata[:, -2, :]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX0sWI8Bc4zG"
      },
      "source": [
        "chnNum=trainx_ds.shape[1]\n",
        "learning_rate=0.002\n",
        "epochs=100\n",
        "step=50 #ms\n",
        "T=1000 #ms\n",
        "totalLen=trainx_ds.shape[2] #ms\n",
        "batch_size=int((totalLen-T)/step) # 280\n",
        "num_T = 3 # (6 conv2d layers) * ( 3 kernel each layer)\n",
        "num_S = 3\n",
        "hidden_size=222\n",
        "dropout=0.2\n",
        "Lambda = 1e-6\n",
        "\n",
        "dataset_train = SEEGDataset1(trainx_ds, trainy_ds,T,step)\n",
        "dataset_val = SEEGDataset1(valx_ds, valy_ds,T,step)\n",
        "dataset_test = SEEGDataset1(testx_ds, testy_ds,T,step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMFsvnRJhExd",
        "outputId": "a65b1a7e-00a6-47c2-9562-1b0300f2a248"
      },
      "source": [
        "len(dataset_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjOmhndXNFUi"
      },
      "source": [
        "#trainy.shape\n",
        "#plt.plot(trainy_ds[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CIQaf0N63aE"
      },
      "source": [
        "train_loader = DataLoader(dataset=dataset_train, batch_size=1, shuffle=True, pin_memory=False)\n",
        "val_loader = DataLoader(dataset=dataset_val, batch_size=1, pin_memory=False)\n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=1, pin_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bYgehRWw3YY"
      },
      "source": [
        "# __init__(self,input_size, sampling_rate, num_T, num_S, hiden, dropout_rate)\n",
        "net = TSception2(chnNum,sampling_rate, num_T, num_S,batch_size).float()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "if(enable_cuda):\n",
        "\tnet.cuda()\n",
        " \n",
        "checkpoint = torch.load(result_dir+'checkpoint195.pth')\n",
        "net.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "124r0ZZh94K8",
        "outputId": "09e688b7-1f3e-4bf7-db8f-4419b061ce85"
      },
      "source": [
        "debugg=False\n",
        "#debugg=True\n",
        "for epoch in range(196,300):\n",
        "    print(\"------ epoch \" + str(epoch) + \" -----\")\n",
        "    net.train()\n",
        "\n",
        "    loss_epoch=0\n",
        "    #trial=0\n",
        "    for trial, (trainx, trainy) in enumerate(train_loader): # ([1, 15000, 19]), ([1, 15000])\n",
        "        #trainy[0,-1]+=0.05\n",
        "        if debugg==True: # just test one trial\n",
        "            if trial == 1:\n",
        "                break\n",
        "                pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if (enable_cuda):\n",
        "            x= trainx.float().cuda()\n",
        "            target = trainy.float().cuda()\n",
        "        y_pred = net(x)\n",
        "        #target = torch.from_numpy(target)\n",
        "\n",
        "        # regularization\n",
        "        loss1 = criterion(y_pred, target.float())\n",
        "        loss2 = regulization(net, Lambda)\n",
        "        #loss3 = y_pred.cpu().detach().numpy()\n",
        "        #loss3 = np.std(np.diff(loss3.reshape(-1)))\n",
        "        loss=loss1+loss2 #+loss3*0.001\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ls=loss1.item()\n",
        "        loss_epoch+=ls\n",
        "        with open(result_dir+ \"trainlose.txt\", \"a\") as f:\n",
        "            f.write(str(loss1) + \"\\n\")\n",
        "    print(\"\"+str(epoch)+\" loss:\"+str(loss_epoch/(trial+1))+\".\")\n",
        "    if epoch % 1 ==0:\n",
        "        net.eval()\n",
        "        print(\"Validating...\")\n",
        "        with torch.no_grad():\n",
        "            vpredAll = []\n",
        "            vtargetAll = []\n",
        "            for trial, (vx, vtarget) in enumerate(val_loader):  # ([1, 15000, 19]), ([1, 15000])                \n",
        "                if (enable_cuda):\n",
        "                    vx= vx.float().cuda()\n",
        "                    vtarget = vtarget.float().cuda()\n",
        "                y_pred = net(vx)\n",
        "                loss3 = criterion(y_pred.squeeze(), vtarget.squeeze())\n",
        "                with open(result_dir+\"testlose.txt\", \"a\") as f:\n",
        "                    f.write(str(loss3) + \"\\n\")\n",
        "\n",
        "                y_pred=y_pred.squeeze().cpu().detach().numpy()\n",
        "                vtarget=vtarget.squeeze().cpu().numpy()\n",
        "                vpredAll.append(y_pred)\n",
        "                vtargetAll.append(vtarget)\n",
        "\n",
        "\n",
        "        vpredAll = np.concatenate(vpredAll,axis=0)\n",
        "        vtargetAll = np.concatenate(vtargetAll, axis=0)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(6, 3))\n",
        "        plt.ion()\n",
        "        ax.clear()\n",
        "        ax.plot(vtargetAll, label=\"True\", linewidth=1)\n",
        "        ax.plot(vpredAll, label='Predicted - Test', linewidth=1)\n",
        "        ax.legend(loc='upper left')\n",
        "        figname = result_dir+'prediction' + str(epoch) + '.png'\n",
        "        fig.savefig(figname)\n",
        "        plt.close(fig)\n",
        "    if epoch % 5==0:\n",
        "        state = {\n",
        "            'state_dict': net.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }\n",
        "        savepath = result_dir+'checkpoint'+str(epoch)+'.pth'\n",
        "        torch.save(state, savepath)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ epoch 196 -----\n",
            "196 loss:0.04963546498852261.\n",
            "Validating...\n",
            "------ epoch 197 -----\n",
            "197 loss:0.04723650940015155.\n",
            "Validating...\n",
            "------ epoch 198 -----\n",
            "198 loss:0.04688021172059037.\n",
            "Validating...\n",
            "------ epoch 199 -----\n",
            "199 loss:0.04671997752166906.\n",
            "Validating...\n",
            "------ epoch 200 -----\n",
            "200 loss:0.04777985209030872.\n",
            "Validating...\n",
            "------ epoch 201 -----\n",
            "201 loss:0.04648004002648137.\n",
            "Validating...\n",
            "------ epoch 202 -----\n",
            "202 loss:0.04702675697330575.\n",
            "Validating...\n",
            "------ epoch 203 -----\n",
            "203 loss:0.0463242298702441.\n",
            "Validating...\n",
            "------ epoch 204 -----\n",
            "204 loss:0.044910610274616944.\n",
            "Validating...\n",
            "------ epoch 205 -----\n",
            "205 loss:0.04367270982445423.\n",
            "Validating...\n",
            "------ epoch 206 -----\n",
            "206 loss:0.046664377208799124.\n",
            "Validating...\n",
            "------ epoch 207 -----\n",
            "207 loss:0.04626473114368016.\n",
            "Validating...\n",
            "------ epoch 208 -----\n",
            "208 loss:0.04822488392750591.\n",
            "Validating...\n",
            "------ epoch 209 -----\n",
            "209 loss:0.044103731874818516.\n",
            "Validating...\n",
            "------ epoch 210 -----\n",
            "210 loss:0.04735364326891505.\n",
            "Validating...\n",
            "------ epoch 211 -----\n",
            "211 loss:0.043435347743995364.\n",
            "Validating...\n",
            "------ epoch 212 -----\n",
            "212 loss:0.04518460266102674.\n",
            "Validating...\n",
            "------ epoch 213 -----\n",
            "213 loss:0.04423452996633063.\n",
            "Validating...\n",
            "------ epoch 214 -----\n",
            "214 loss:0.0446686555663029.\n",
            "Validating...\n",
            "------ epoch 215 -----\n",
            "215 loss:0.04737643701797825.\n",
            "Validating...\n",
            "------ epoch 216 -----\n",
            "216 loss:0.04446508211746686.\n",
            "Validating...\n",
            "------ epoch 217 -----\n",
            "217 loss:0.042303810547248036.\n",
            "Validating...\n",
            "------ epoch 218 -----\n",
            "218 loss:0.04313183224254872.\n",
            "Validating...\n",
            "------ epoch 219 -----\n",
            "219 loss:0.04057760755689341.\n",
            "Validating...\n",
            "------ epoch 220 -----\n",
            "220 loss:0.041614776489056524.\n",
            "Validating...\n",
            "------ epoch 221 -----\n",
            "221 loss:0.040337712085663766.\n",
            "Validating...\n",
            "------ epoch 222 -----\n",
            "222 loss:0.04244784266151235.\n",
            "Validating...\n",
            "------ epoch 223 -----\n",
            "223 loss:0.04138773148958334.\n",
            "Validating...\n",
            "------ epoch 224 -----\n",
            "224 loss:0.04002940673302165.\n",
            "Validating...\n",
            "------ epoch 225 -----\n",
            "225 loss:0.04092352014129697.\n",
            "Validating...\n",
            "------ epoch 226 -----\n",
            "226 loss:0.04226386573134085.\n",
            "Validating...\n",
            "------ epoch 227 -----\n",
            "227 loss:0.040791501729133525.\n",
            "Validating...\n",
            "------ epoch 228 -----\n",
            "228 loss:0.0399095914800162.\n",
            "Validating...\n",
            "------ epoch 229 -----\n",
            "229 loss:0.04116594916114868.\n",
            "Validating...\n",
            "------ epoch 230 -----\n",
            "230 loss:0.0398328938300453.\n",
            "Validating...\n",
            "------ epoch 231 -----\n",
            "231 loss:0.037044326119693154.\n",
            "Validating...\n",
            "------ epoch 232 -----\n",
            "232 loss:0.03805139564545983.\n",
            "Validating...\n",
            "------ epoch 233 -----\n",
            "233 loss:0.03808578346871724.\n",
            "Validating...\n",
            "------ epoch 234 -----\n",
            "234 loss:0.03781404787027356.\n",
            "Validating...\n",
            "------ epoch 235 -----\n",
            "235 loss:0.03806836933086989.\n",
            "Validating...\n",
            "------ epoch 236 -----\n",
            "236 loss:0.03895820659916785.\n",
            "Validating...\n",
            "------ epoch 237 -----\n",
            "237 loss:0.03710897446025984.\n",
            "Validating...\n",
            "------ epoch 238 -----\n",
            "238 loss:0.03566420138655704.\n",
            "Validating...\n",
            "------ epoch 239 -----\n",
            "239 loss:0.03822060488559053.\n",
            "Validating...\n",
            "------ epoch 240 -----\n",
            "240 loss:0.038166419247765156.\n",
            "Validating...\n",
            "------ epoch 241 -----\n",
            "241 loss:0.03603619982299032.\n",
            "Validating...\n",
            "------ epoch 242 -----\n",
            "242 loss:0.03794375362695526.\n",
            "Validating...\n",
            "------ epoch 243 -----\n",
            "243 loss:0.03575067831029705.\n",
            "Validating...\n",
            "------ epoch 244 -----\n",
            "244 loss:0.03837514477703026.\n",
            "Validating...\n",
            "------ epoch 245 -----\n",
            "245 loss:0.03764964172506105.\n",
            "Validating...\n",
            "------ epoch 246 -----\n",
            "246 loss:0.0362661853274804.\n",
            "Validating...\n",
            "------ epoch 247 -----\n",
            "247 loss:0.03690778379628466.\n",
            "Validating...\n",
            "------ epoch 248 -----\n",
            "248 loss:0.03817063125276591.\n",
            "Validating...\n",
            "------ epoch 249 -----\n",
            "249 loss:0.035129831531637554.\n",
            "Validating...\n",
            "------ epoch 250 -----\n",
            "250 loss:0.03534771201311279.\n",
            "Validating...\n",
            "------ epoch 251 -----\n",
            "251 loss:0.03483533354918078.\n",
            "Validating...\n",
            "------ epoch 252 -----\n",
            "252 loss:0.03635920105912423.\n",
            "Validating...\n",
            "------ epoch 253 -----\n",
            "253 loss:0.03363783520614823.\n",
            "Validating...\n",
            "------ epoch 254 -----\n",
            "254 loss:0.034373125215297784.\n",
            "Validating...\n",
            "------ epoch 255 -----\n",
            "255 loss:0.03511056964980217.\n",
            "Validating...\n",
            "------ epoch 256 -----\n",
            "256 loss:0.0357297777742842.\n",
            "Validating...\n",
            "------ epoch 257 -----\n",
            "257 loss:0.03457405991552366.\n",
            "Validating...\n",
            "------ epoch 258 -----\n",
            "258 loss:0.034470091068769915.\n",
            "Validating...\n",
            "------ epoch 259 -----\n",
            "259 loss:0.034960694362456766.\n",
            "Validating...\n",
            "------ epoch 260 -----\n",
            "260 loss:0.03423684063146554.\n",
            "Validating...\n",
            "------ epoch 261 -----\n",
            "261 loss:0.03308930237367118.\n",
            "Validating...\n",
            "------ epoch 262 -----\n",
            "262 loss:0.03240972161450881.\n",
            "Validating...\n",
            "------ epoch 263 -----\n",
            "263 loss:0.03476979581528675.\n",
            "Validating...\n",
            "------ epoch 264 -----\n",
            "264 loss:0.03090548737100878.\n",
            "Validating...\n",
            "------ epoch 265 -----\n",
            "265 loss:0.03449737145644376.\n",
            "Validating...\n",
            "------ epoch 266 -----\n",
            "266 loss:0.03045182048848246.\n",
            "Validating...\n",
            "------ epoch 267 -----\n",
            "267 loss:0.03362831625282386.\n",
            "Validating...\n",
            "------ epoch 268 -----\n",
            "268 loss:0.03223500141116269.\n",
            "Validating...\n",
            "------ epoch 269 -----\n",
            "269 loss:0.03241043344881954.\n",
            "Validating...\n",
            "------ epoch 270 -----\n",
            "270 loss:0.03564868499998445.\n",
            "Validating...\n",
            "------ epoch 271 -----\n",
            "271 loss:0.031175704728180573.\n",
            "Validating...\n",
            "------ epoch 272 -----\n",
            "272 loss:0.030012329771988474.\n",
            "Validating...\n",
            "------ epoch 273 -----\n",
            "273 loss:0.03612945151467949.\n",
            "Validating...\n",
            "------ epoch 274 -----\n",
            "274 loss:0.03341028445905422.\n",
            "Validating...\n",
            "------ epoch 275 -----\n",
            "275 loss:0.03398525619374241.\n",
            "Validating...\n",
            "------ epoch 276 -----\n",
            "276 loss:0.03409157732848899.\n",
            "Validating...\n",
            "------ epoch 277 -----\n",
            "277 loss:0.03398406117665187.\n",
            "Validating...\n",
            "------ epoch 278 -----\n",
            "278 loss:0.03146200801119587.\n",
            "Validating...\n",
            "------ epoch 279 -----\n",
            "279 loss:0.0344697141909372.\n",
            "Validating...\n",
            "------ epoch 280 -----\n",
            "280 loss:0.03081527379167787.\n",
            "Validating...\n",
            "------ epoch 281 -----\n",
            "281 loss:0.030083743993477043.\n",
            "Validating...\n",
            "------ epoch 282 -----\n",
            "282 loss:0.02974865866540852.\n",
            "Validating...\n",
            "------ epoch 283 -----\n",
            "283 loss:0.03186350707280434.\n",
            "Validating...\n",
            "------ epoch 284 -----\n",
            "284 loss:0.031015825394730447.\n",
            "Validating...\n",
            "------ epoch 285 -----\n",
            "285 loss:0.029993611076152175.\n",
            "Validating...\n",
            "------ epoch 286 -----\n",
            "286 loss:0.02903848660367904.\n",
            "Validating...\n",
            "------ epoch 287 -----\n",
            "287 loss:0.030669677126521275.\n",
            "Validating...\n",
            "------ epoch 288 -----\n",
            "288 loss:0.03280013088547325.\n",
            "Validating...\n",
            "------ epoch 289 -----\n",
            "289 loss:0.03151464079096282.\n",
            "Validating...\n",
            "------ epoch 290 -----\n",
            "290 loss:0.029352612434333916.\n",
            "Validating...\n",
            "------ epoch 291 -----\n",
            "291 loss:0.029178541157615638.\n",
            "Validating...\n",
            "------ epoch 292 -----\n",
            "292 loss:0.02824015865276047.\n",
            "Validating...\n",
            "------ epoch 293 -----\n",
            "293 loss:0.030914019146081755.\n",
            "Validating...\n",
            "------ epoch 294 -----\n",
            "294 loss:0.030188754674489216.\n",
            "Validating...\n",
            "------ epoch 295 -----\n",
            "295 loss:0.02959298773400359.\n",
            "Validating...\n",
            "------ epoch 296 -----\n",
            "296 loss:0.028779185617784576.\n",
            "Validating...\n",
            "------ epoch 297 -----\n",
            "297 loss:0.029993922291797096.\n",
            "Validating...\n",
            "------ epoch 298 -----\n",
            "298 loss:0.030036211574166003.\n",
            "Validating...\n",
            "------ epoch 299 -----\n",
            "299 loss:0.028057863702997565.\n",
            "Validating...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Ml_yK3Wvpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}